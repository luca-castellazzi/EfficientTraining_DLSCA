{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74ade341-3ad7-4967-8e77-3126e098be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import trsfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation, Conv1D, MaxPool1D, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import L1, L2, L1L2\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Custom\n",
    "import sys\n",
    "sys.path.insert(0, '../../src/utils')\n",
    "from data_loader import DataLoader, SplitDataLoader\n",
    "import constants\n",
    "import aes\n",
    "# sys.path.insert(0, '../../src/modeling')\n",
    "# from network import Network\n",
    "\n",
    "# Suppress TensorFlow messages\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' # 1 for INFO, 2 for INFO & WARNINGs, 3 for INFO & WARNINGs & ERRORs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0374c24f-b2b2-4495-8b94-40680247949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(hp, input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=hp['filters'], \n",
    "                     kernel_size=hp['kernel_size'], \n",
    "                     activation='relu',\n",
    "                     # kernel_initializer='random_uniform',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPool1D(pool_size=hp['pool_size']))\n",
    "    \n",
    "    for _ in range(hp['hidden_conv']):\n",
    "        model.add(Conv1D(filters=hp['hidden_conv_filters'], \n",
    "                         kernel_size=hp['hidden_conv_kernel_size'], \n",
    "                         # kernel_initializer='random_uniform',\n",
    "                         activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(MaxPool1D(pool_size=hp['hidden_conv_pool_size']))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for _ in range(hp['hidden_dense']):\n",
    "        model.add(Dense(hp['hidden_dense_neurons'], activation='relu'))\n",
    "        \n",
    "    model.add(Dense(256, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def CNN_images(hp, input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=hp['filters'], \n",
    "                     kernel_size=hp['kernel_size'], \n",
    "                     activation='relu',\n",
    "                     # kernel_initializer='random_uniform',\n",
    "                     input_shape=input_shape))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(MaxPool2D(pool_size=hp['pool_size']))\n",
    "    \n",
    "    # for _ in range(hp['hidden_conv']):\n",
    "    #     model.add(Conv2D(filters=hp['hidden_conv_filters'], \n",
    "    #                      kernel_size=hp['hidden_conv_kernel_size'], \n",
    "    #                      # kernel_initializer='random_uniform',\n",
    "    #                      activation='relu'))\n",
    "    #     # model.add(Dropout(0.2))\n",
    "    #     model.add(MaxPool2D(pool_size=hp['hidden_conv_pool_size']))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for _ in range(hp['hidden_dense']):\n",
    "        model.add(Dense(hp['hidden_dense_neurons'], activation='relu'))\n",
    "        \n",
    "    model.add(Dense(256, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb3e93c7-b94c-4361-a10a-292fb9f99cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HP = {\n",
    "#     'filters': 16,\n",
    "#     'kernel_size': 8,\n",
    "#     'pool_size': 2,\n",
    "#     'hidden_conv': 3,\n",
    "#     'hidden_conv_filters': 8,\n",
    "#     'hidden_conv_kernel_size': 8,\n",
    "#     'hidden_conv_pool_size': 2,\n",
    "#     'hidden_dense': 3,\n",
    "#     'hidden_dense_neurons': 40,\n",
    "#     'batch_size': 100\n",
    "# }\n",
    "\n",
    "HP = {\n",
    "    'filters': 16,\n",
    "    'kernel_size': 8,\n",
    "    'pool_size': 2,\n",
    "    'hidden_conv': 2,\n",
    "    'hidden_conv_filters': 8,\n",
    "    'hidden_conv_kernel_size': 8,\n",
    "    'hidden_conv_pool_size': 2,\n",
    "    'hidden_dense': 3,\n",
    "    'hidden_dense_neurons': 40,\n",
    "    'batch_size': 128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a84be96-a611-47d3-8c58-3b3948a02200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import trsfile\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pyts.image import GramianAngularField\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "class DataLoader():\n",
    "\n",
    "\n",
    "    def __init__(self, configs, n_tot_traces, target, byte_idx=None):\n",
    "        \n",
    "        self.trace_files = [f'{constants.CURR_TRACES_PATH}/{c}_500MHz + Resampled.trs' \n",
    "                            for c in configs]\n",
    "                            \n",
    "        self.n_tr_per_config = int(n_tot_traces / len(configs))\n",
    "        \n",
    "        self.byte_idx = byte_idx\n",
    "        \n",
    "        self.target = target\n",
    "        self.n_classes = constants.N_CLASSES[target]\n",
    "        \n",
    "        self.gaf = GramianAngularField(image_size=64, method='s')\n",
    "        \n",
    "        # self.scaler = StandardScaler()\n",
    "        \n",
    "    \n",
    "    def _retrieve_metadata(self, tr):\n",
    "\n",
    "        p = np.array(tr.get_input()) # int list\n",
    "        k = np.array(tr.get_key()) # int list\n",
    "        l = aes.labels_from_key(p, k, self.target) # Compute the set of 16 labels\n",
    "\n",
    "        if self.byte_idx is not None:\n",
    "            l = l[self.byte_idx]\n",
    "            p = p[self.byte_idx]\n",
    "            k = k[self.byte_idx]\n",
    "\n",
    "        l = to_categorical(l, self.n_classes)\n",
    "        \n",
    "        return l, p, k\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def _shuffle(x, y, pbs, tkbs):\n",
    "        \n",
    "        to_shuffle = list(zip(x, y, pbs, tkbs))\n",
    "        random.shuffle(to_shuffle)\n",
    "        x, y, pbs, tkbs = zip(*to_shuffle)\n",
    "        \n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        pbs = np.array(pbs)\n",
    "        tkbs = np.array(tkbs)\n",
    "        \n",
    "        return x, y, pbs, tkbs\n",
    "        \n",
    "        \n",
    "    def load(self):\n",
    "    \n",
    "        samples = []\n",
    "        labels = []\n",
    "        pltxt_bytes = []\n",
    "        true_key_bytes = []\n",
    "        \n",
    "        for tfile in self.trace_files:\n",
    "            with trsfile.open(tfile, 'r') as traces:\n",
    "                for tr in traces[:self.n_tr_per_config]:\n",
    "                    s = tr.samples\n",
    "                    l, p, k = self._retrieve_metadata(tr)\n",
    "                    samples.append(s)\n",
    "                    labels.append(l)\n",
    "                    pltxt_bytes.append(p)\n",
    "                    true_key_bytes.append(k)\n",
    "                    \n",
    "        x = np.array(samples) # (n_tot_traces x trace_len)\n",
    "        # x = self.scaler.fit_transform(x)\n",
    "        y = np.array(labels) # (n_tot_traces x n_classes)\n",
    "        pbs = np.array(pltxt_bytes) # (n_tot_traces x 1)\n",
    "        tkbs = np.array(true_key_bytes) # (n_tot_traces x 1)\n",
    "        \n",
    "        x, y, pbs, tkbs = self._shuffle(x, y, pbs, tkbs)\n",
    "        \n",
    "        if len(self.trace_files) == 1:\n",
    "            tkbs = tkbs[0] # All true_key_bytes are equal because the config is unique \n",
    "        \n",
    "        x = self.gaf.fit_transform(x)\n",
    "        \n",
    "        return x, y, pbs, tkbs\n",
    "        \n",
    "        \n",
    "class SplitDataLoader(DataLoader):\n",
    "   \n",
    "    def __init__(self, configs, n_tot_traces, train_size, target, byte_idx=None):\n",
    "        \n",
    "        super().__init__(configs, n_tot_traces, target, byte_idx)\n",
    "        \n",
    "        self.n_train_tr_per_config = int(train_size * self.n_tr_per_config)\n",
    "        \n",
    "        \n",
    "    def load(self):\n",
    "    \n",
    "        x_train = []\n",
    "        y_train = []\n",
    "        pbs_train = []\n",
    "        tkbs_train = []\n",
    "        \n",
    "        x_val = []\n",
    "        y_val = []\n",
    "        pbs_val = []\n",
    "        tkbs_val = []\n",
    "        \n",
    "        for tfile in self.trace_files:\n",
    "            \n",
    "            config_s = []\n",
    "            config_l = []\n",
    "            config_p = []\n",
    "            config_k = []\n",
    "            \n",
    "            with trsfile.open(tfile, 'r') as traces:\n",
    "                for tr in traces[:self.n_tr_per_config]:\n",
    "                    s = tr.samples\n",
    "                    l, p, k = self._retrieve_metadata(tr)\n",
    "                    \n",
    "                    config_s.append(s)\n",
    "                    config_l.append(l)\n",
    "                    config_p.append(p)\n",
    "                    config_k.append(k)\n",
    "            \n",
    "            x_train.append(config_s[:self.n_train_tr_per_config])\n",
    "            x_val.append(config_s[self.n_train_tr_per_config:])\n",
    "            \n",
    "            y_train.append(config_l[:self.n_train_tr_per_config])\n",
    "            y_val.append(config_l[self.n_train_tr_per_config:])\n",
    "            \n",
    "            pbs_train.append(config_p[:self.n_train_tr_per_config])\n",
    "            pbs_val.append(config_p[self.n_train_tr_per_config:])\n",
    "            \n",
    "            tkbs_train.append(config_k[:self.n_train_tr_per_config])\n",
    "            tkbs_val.append(config_k[self.n_train_tr_per_config:])\n",
    "        \n",
    "        # Reduce the lists of arrays to a single np.ndarray\n",
    "        x_train = np.concatenate(x_train)\n",
    "        y_train = np.concatenate(y_train)\n",
    "        pbs_train = np.concatenate(pbs_train)\n",
    "        tkbs_train = np.concatenate(tkbs_train)\n",
    "        \n",
    "        x_val = np.concatenate(x_val)\n",
    "        y_val = np.concatenate(y_val)\n",
    "        pbs_val = np.concatenate(pbs_val)\n",
    "        tkbs_val = np.concatenate(tkbs_val)\n",
    "        \n",
    "        # Scale the whole train-set (train + val) with the same scaler\n",
    "        n_tot_train = x_train.shape[0] # train_size * n_tot_traces\n",
    "        x_tot = np.concatenate([x_train, x_val])\n",
    "        # x_tot = self.scaler.fit_transform(x_tot)\n",
    "        x_train = x_tot[:n_tot_train]\n",
    "        x_val = x_tot[n_tot_train:]\n",
    "        \n",
    "        # Shuffle the sets\n",
    "        x_train, y_train, pbs_train, tkbs_train = self._shuffle(x_train, y_train, pbs_train, tkbs_train)\n",
    "        x_val, y_val, pbs_val, tkbs_val = self._shuffle(x_val, y_val, pbs_val, tkbs_val) \n",
    "            \n",
    "        x_train = self.gaf.fit_transform(x_train)\n",
    "        x_val = self.gaf.fit_transform(x_val)\n",
    "            \n",
    "        # Create train and test packages\n",
    "        train_data = (x_train, y_train, pbs_train, tkbs_train)\n",
    "        val_data = (x_val, y_val, pbs_val, tkbs_val)\n",
    "            \n",
    "        return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec0c3789-3806-466f-9d87-3ab3b57b2fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss', \n",
    "                patience=15\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.2,\n",
    "                patience=7,\n",
    "                min_lr=1e-7),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82db7e09-c3cb-4f4b-9d20-dd95472a48b9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "704/704 [==============================] - 3s 4ms/step - loss: 5.5449 - accuracy: 0.0039 - val_loss: 5.5412 - val_accuracy: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 2/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 5.4459 - accuracy: 0.0074 - val_loss: 5.3546 - val_accuracy: 0.0091 - lr: 1.0000e-04\n",
      "Epoch 3/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 5.3040 - accuracy: 0.0085 - val_loss: 5.2471 - val_accuracy: 0.0097 - lr: 1.0000e-04\n",
      "Epoch 4/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 5.2099 - accuracy: 0.0100 - val_loss: 5.1671 - val_accuracy: 0.0128 - lr: 1.0000e-04\n",
      "Epoch 5/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 5.1383 - accuracy: 0.0116 - val_loss: 5.1054 - val_accuracy: 0.0139 - lr: 1.0000e-04\n",
      "Epoch 6/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 5.0852 - accuracy: 0.0131 - val_loss: 5.0688 - val_accuracy: 0.0138 - lr: 1.0000e-04\n",
      "Epoch 7/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 5.0491 - accuracy: 0.0143 - val_loss: 5.0349 - val_accuracy: 0.0147 - lr: 1.0000e-04\n",
      "Epoch 8/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 5.0235 - accuracy: 0.0161 - val_loss: 5.0184 - val_accuracy: 0.0159 - lr: 1.0000e-04\n",
      "Epoch 9/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 5.0027 - accuracy: 0.0165 - val_loss: 4.9939 - val_accuracy: 0.0161 - lr: 1.0000e-04\n",
      "Epoch 10/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.9827 - accuracy: 0.0165 - val_loss: 4.9924 - val_accuracy: 0.0167 - lr: 1.0000e-04\n",
      "Epoch 11/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.9676 - accuracy: 0.0168 - val_loss: 4.9583 - val_accuracy: 0.0167 - lr: 1.0000e-04\n",
      "Epoch 12/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.9532 - accuracy: 0.0173 - val_loss: 4.9421 - val_accuracy: 0.0176 - lr: 1.0000e-04\n",
      "Epoch 13/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.9376 - accuracy: 0.0177 - val_loss: 4.9446 - val_accuracy: 0.0178 - lr: 1.0000e-04\n",
      "Epoch 14/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.9227 - accuracy: 0.0184 - val_loss: 4.9180 - val_accuracy: 0.0186 - lr: 1.0000e-04\n",
      "Epoch 15/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.9100 - accuracy: 0.0187 - val_loss: 4.9019 - val_accuracy: 0.0191 - lr: 1.0000e-04\n",
      "Epoch 16/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.8974 - accuracy: 0.0183 - val_loss: 4.8899 - val_accuracy: 0.0202 - lr: 1.0000e-04\n",
      "Epoch 17/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.8875 - accuracy: 0.0190 - val_loss: 4.8857 - val_accuracy: 0.0189 - lr: 1.0000e-04\n",
      "Epoch 18/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.8770 - accuracy: 0.0191 - val_loss: 4.8737 - val_accuracy: 0.0205 - lr: 1.0000e-04\n",
      "Epoch 19/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.8689 - accuracy: 0.0194 - val_loss: 4.8730 - val_accuracy: 0.0189 - lr: 1.0000e-04\n",
      "Epoch 20/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.8601 - accuracy: 0.0194 - val_loss: 4.8569 - val_accuracy: 0.0226 - lr: 1.0000e-04\n",
      "Epoch 21/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.8523 - accuracy: 0.0195 - val_loss: 4.8493 - val_accuracy: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 22/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.8499 - accuracy: 0.0197 - val_loss: 4.8449 - val_accuracy: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 23/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.8413 - accuracy: 0.0204 - val_loss: 4.8410 - val_accuracy: 0.0226 - lr: 1.0000e-04\n",
      "Epoch 24/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.8357 - accuracy: 0.0202 - val_loss: 4.8359 - val_accuracy: 0.0216 - lr: 1.0000e-04\n",
      "Epoch 25/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.8308 - accuracy: 0.0197 - val_loss: 4.8364 - val_accuracy: 0.0213 - lr: 1.0000e-04\n",
      "Epoch 26/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.8255 - accuracy: 0.0203 - val_loss: 4.8367 - val_accuracy: 0.0200 - lr: 1.0000e-04\n",
      "Epoch 27/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.8219 - accuracy: 0.0205 - val_loss: 4.8217 - val_accuracy: 0.0219 - lr: 1.0000e-04\n",
      "Epoch 28/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.8154 - accuracy: 0.0205 - val_loss: 4.8196 - val_accuracy: 0.0221 - lr: 1.0000e-04\n",
      "Epoch 29/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.8111 - accuracy: 0.0209 - val_loss: 4.8099 - val_accuracy: 0.0239 - lr: 1.0000e-04\n",
      "Epoch 30/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.8069 - accuracy: 0.0202 - val_loss: 4.8113 - val_accuracy: 0.0224 - lr: 1.0000e-04\n",
      "Epoch 31/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.8027 - accuracy: 0.0207 - val_loss: 4.8007 - val_accuracy: 0.0239 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7994 - accuracy: 0.0208 - val_loss: 4.7997 - val_accuracy: 0.0223 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7955 - accuracy: 0.0209 - val_loss: 4.7937 - val_accuracy: 0.0213 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7903 - accuracy: 0.0215 - val_loss: 4.7948 - val_accuracy: 0.0229 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7867 - accuracy: 0.0208 - val_loss: 4.7847 - val_accuracy: 0.0239 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7824 - accuracy: 0.0208 - val_loss: 4.7858 - val_accuracy: 0.0236 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7813 - accuracy: 0.0206 - val_loss: 4.7855 - val_accuracy: 0.0203 - lr: 1.0000e-04\n",
      "Epoch 38/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7762 - accuracy: 0.0209 - val_loss: 4.7790 - val_accuracy: 0.0204 - lr: 1.0000e-04\n",
      "Epoch 39/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7736 - accuracy: 0.0204 - val_loss: 4.7767 - val_accuracy: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 40/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7699 - accuracy: 0.0211 - val_loss: 4.8269 - val_accuracy: 0.0195 - lr: 1.0000e-04\n",
      "Epoch 41/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7682 - accuracy: 0.0213 - val_loss: 4.7671 - val_accuracy: 0.0232 - lr: 1.0000e-04\n",
      "Epoch 42/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7643 - accuracy: 0.0206 - val_loss: 4.7778 - val_accuracy: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 43/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7615 - accuracy: 0.0214 - val_loss: 4.7612 - val_accuracy: 0.0233 - lr: 1.0000e-04\n",
      "Epoch 44/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7577 - accuracy: 0.0213 - val_loss: 4.7839 - val_accuracy: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 45/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7577 - accuracy: 0.0204 - val_loss: 4.7563 - val_accuracy: 0.0229 - lr: 1.0000e-04\n",
      "Epoch 46/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7548 - accuracy: 0.0212 - val_loss: 4.7542 - val_accuracy: 0.0226 - lr: 1.0000e-04\n",
      "Epoch 47/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7507 - accuracy: 0.0207 - val_loss: 4.7509 - val_accuracy: 0.0214 - lr: 1.0000e-04\n",
      "Epoch 48/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7490 - accuracy: 0.0215 - val_loss: 4.7511 - val_accuracy: 0.0231 - lr: 1.0000e-04\n",
      "Epoch 49/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7461 - accuracy: 0.0214 - val_loss: 4.7530 - val_accuracy: 0.0220 - lr: 1.0000e-04\n",
      "Epoch 50/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7439 - accuracy: 0.0210 - val_loss: 4.7469 - val_accuracy: 0.0237 - lr: 1.0000e-04\n",
      "Epoch 51/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7415 - accuracy: 0.0217 - val_loss: 4.7471 - val_accuracy: 0.0213 - lr: 1.0000e-04\n",
      "Epoch 52/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7409 - accuracy: 0.0219 - val_loss: 4.7835 - val_accuracy: 0.0206 - lr: 1.0000e-04\n",
      "Epoch 53/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7385 - accuracy: 0.0208 - val_loss: 4.7393 - val_accuracy: 0.0225 - lr: 1.0000e-04\n",
      "Epoch 54/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7359 - accuracy: 0.0213 - val_loss: 4.7388 - val_accuracy: 0.0219 - lr: 1.0000e-04\n",
      "Epoch 55/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7345 - accuracy: 0.0212 - val_loss: 4.7395 - val_accuracy: 0.0217 - lr: 1.0000e-04\n",
      "Epoch 56/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7311 - accuracy: 0.0224 - val_loss: 4.7342 - val_accuracy: 0.0225 - lr: 1.0000e-04\n",
      "Epoch 57/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7306 - accuracy: 0.0213 - val_loss: 4.7377 - val_accuracy: 0.0226 - lr: 1.0000e-04\n",
      "Epoch 58/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7288 - accuracy: 0.0211 - val_loss: 4.7320 - val_accuracy: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 59/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7257 - accuracy: 0.0215 - val_loss: 4.7322 - val_accuracy: 0.0216 - lr: 1.0000e-04\n",
      "Epoch 60/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7244 - accuracy: 0.0214 - val_loss: 4.7362 - val_accuracy: 0.0228 - lr: 1.0000e-04\n",
      "Epoch 61/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7215 - accuracy: 0.0214 - val_loss: 4.7653 - val_accuracy: 0.0236 - lr: 1.0000e-04\n",
      "Epoch 62/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7207 - accuracy: 0.0217 - val_loss: 4.7255 - val_accuracy: 0.0225 - lr: 1.0000e-04\n",
      "Epoch 63/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7173 - accuracy: 0.0215 - val_loss: 4.7538 - val_accuracy: 0.0191 - lr: 1.0000e-04\n",
      "Epoch 64/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7157 - accuracy: 0.0214 - val_loss: 4.7304 - val_accuracy: 0.0216 - lr: 1.0000e-04\n",
      "Epoch 65/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7182 - accuracy: 0.0214 - val_loss: 4.7733 - val_accuracy: 0.0218 - lr: 1.0000e-04\n",
      "Epoch 66/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7166 - accuracy: 0.0214 - val_loss: 4.7163 - val_accuracy: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 67/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7123 - accuracy: 0.0210 - val_loss: 4.7230 - val_accuracy: 0.0231 - lr: 1.0000e-04\n",
      "Epoch 68/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7111 - accuracy: 0.0210 - val_loss: 4.7915 - val_accuracy: 0.0206 - lr: 1.0000e-04\n",
      "Epoch 69/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7082 - accuracy: 0.0212 - val_loss: 4.7391 - val_accuracy: 0.0185 - lr: 1.0000e-04\n",
      "Epoch 70/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7073 - accuracy: 0.0213 - val_loss: 4.7426 - val_accuracy: 0.0228 - lr: 1.0000e-04\n",
      "Epoch 71/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7082 - accuracy: 0.0213 - val_loss: 4.7110 - val_accuracy: 0.0221 - lr: 1.0000e-04\n",
      "Epoch 72/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7054 - accuracy: 0.0211 - val_loss: 4.7075 - val_accuracy: 0.0239 - lr: 1.0000e-04\n",
      "Epoch 73/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7040 - accuracy: 0.0217 - val_loss: 4.7069 - val_accuracy: 0.0227 - lr: 1.0000e-04\n",
      "Epoch 74/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.7024 - accuracy: 0.0214 - val_loss: 4.7074 - val_accuracy: 0.0226 - lr: 1.0000e-04\n",
      "Epoch 75/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6990 - accuracy: 0.0213 - val_loss: 4.7117 - val_accuracy: 0.0230 - lr: 1.0000e-04\n",
      "Epoch 76/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6981 - accuracy: 0.0220 - val_loss: 4.7093 - val_accuracy: 0.0230 - lr: 1.0000e-04\n",
      "Epoch 77/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6985 - accuracy: 0.0215 - val_loss: 4.7046 - val_accuracy: 0.0239 - lr: 1.0000e-04\n",
      "Epoch 78/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6965 - accuracy: 0.0213 - val_loss: 4.7212 - val_accuracy: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 79/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6956 - accuracy: 0.0220 - val_loss: 4.7000 - val_accuracy: 0.0230 - lr: 1.0000e-04\n",
      "Epoch 80/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6920 - accuracy: 0.0223 - val_loss: 4.7004 - val_accuracy: 0.0222 - lr: 1.0000e-04\n",
      "Epoch 81/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6933 - accuracy: 0.0221 - val_loss: 4.7076 - val_accuracy: 0.0200 - lr: 1.0000e-04\n",
      "Epoch 82/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6908 - accuracy: 0.0218 - val_loss: 4.6984 - val_accuracy: 0.0215 - lr: 1.0000e-04\n",
      "Epoch 83/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6898 - accuracy: 0.0223 - val_loss: 4.6955 - val_accuracy: 0.0222 - lr: 1.0000e-04\n",
      "Epoch 84/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6885 - accuracy: 0.0225 - val_loss: 4.6994 - val_accuracy: 0.0223 - lr: 1.0000e-04\n",
      "Epoch 85/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6871 - accuracy: 0.0220 - val_loss: 4.7290 - val_accuracy: 0.0204 - lr: 1.0000e-04\n",
      "Epoch 86/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6865 - accuracy: 0.0221 - val_loss: 4.6927 - val_accuracy: 0.0216 - lr: 1.0000e-04\n",
      "Epoch 87/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6885 - accuracy: 0.0222 - val_loss: 4.6940 - val_accuracy: 0.0216 - lr: 1.0000e-04\n",
      "Epoch 88/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6838 - accuracy: 0.0221 - val_loss: 4.6978 - val_accuracy: 0.0241 - lr: 1.0000e-04\n",
      "Epoch 89/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6850 - accuracy: 0.0218 - val_loss: 4.6877 - val_accuracy: 0.0254 - lr: 1.0000e-04\n",
      "Epoch 90/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6816 - accuracy: 0.0230 - val_loss: 4.6885 - val_accuracy: 0.0239 - lr: 1.0000e-04\n",
      "Epoch 91/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6806 - accuracy: 0.0226 - val_loss: 4.6866 - val_accuracy: 0.0239 - lr: 1.0000e-04\n",
      "Epoch 92/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6782 - accuracy: 0.0232 - val_loss: 4.6931 - val_accuracy: 0.0216 - lr: 1.0000e-04\n",
      "Epoch 93/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6795 - accuracy: 0.0233 - val_loss: 4.6875 - val_accuracy: 0.0212 - lr: 1.0000e-04\n",
      "Epoch 94/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6762 - accuracy: 0.0232 - val_loss: 4.6907 - val_accuracy: 0.0201 - lr: 1.0000e-04\n",
      "Epoch 95/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6770 - accuracy: 0.0227 - val_loss: 4.6886 - val_accuracy: 0.0227 - lr: 1.0000e-04\n",
      "Epoch 96/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6759 - accuracy: 0.0232 - val_loss: 4.6911 - val_accuracy: 0.0226 - lr: 1.0000e-04\n",
      "Epoch 97/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6744 - accuracy: 0.0229 - val_loss: 4.6806 - val_accuracy: 0.0232 - lr: 1.0000e-04\n",
      "Epoch 98/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6724 - accuracy: 0.0232 - val_loss: 4.6915 - val_accuracy: 0.0227 - lr: 1.0000e-04\n",
      "Epoch 99/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6727 - accuracy: 0.0225 - val_loss: 4.6858 - val_accuracy: 0.0220 - lr: 1.0000e-04\n",
      "Epoch 100/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6702 - accuracy: 0.0228 - val_loss: 4.6891 - val_accuracy: 0.0236 - lr: 1.0000e-04\n",
      "Epoch 101/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6707 - accuracy: 0.0233 - val_loss: 4.6793 - val_accuracy: 0.0237 - lr: 1.0000e-04\n",
      "Epoch 102/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6685 - accuracy: 0.0236 - val_loss: 4.6805 - val_accuracy: 0.0213 - lr: 1.0000e-04\n",
      "Epoch 103/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6680 - accuracy: 0.0230 - val_loss: 4.6773 - val_accuracy: 0.0232 - lr: 1.0000e-04\n",
      "Epoch 104/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6659 - accuracy: 0.0231 - val_loss: 4.6812 - val_accuracy: 0.0224 - lr: 1.0000e-04\n",
      "Epoch 105/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6676 - accuracy: 0.0239 - val_loss: 4.6783 - val_accuracy: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 106/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6639 - accuracy: 0.0227 - val_loss: 4.6810 - val_accuracy: 0.0235 - lr: 1.0000e-04\n",
      "Epoch 107/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6632 - accuracy: 0.0236 - val_loss: 4.6734 - val_accuracy: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 108/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6606 - accuracy: 0.0235 - val_loss: 4.6937 - val_accuracy: 0.0193 - lr: 1.0000e-04\n",
      "Epoch 109/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6621 - accuracy: 0.0232 - val_loss: 4.6702 - val_accuracy: 0.0228 - lr: 1.0000e-04\n",
      "Epoch 110/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6609 - accuracy: 0.0238 - val_loss: 4.6682 - val_accuracy: 0.0253 - lr: 1.0000e-04\n",
      "Epoch 111/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6607 - accuracy: 0.0242 - val_loss: 4.6857 - val_accuracy: 0.0233 - lr: 1.0000e-04\n",
      "Epoch 112/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6605 - accuracy: 0.0232 - val_loss: 4.6764 - val_accuracy: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 113/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6598 - accuracy: 0.0235 - val_loss: 4.6665 - val_accuracy: 0.0228 - lr: 1.0000e-04\n",
      "Epoch 114/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6580 - accuracy: 0.0237 - val_loss: 4.6637 - val_accuracy: 0.0236 - lr: 1.0000e-04\n",
      "Epoch 115/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6555 - accuracy: 0.0237 - val_loss: 4.6666 - val_accuracy: 0.0225 - lr: 1.0000e-04\n",
      "Epoch 116/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6563 - accuracy: 0.0240 - val_loss: 4.6802 - val_accuracy: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 117/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6525 - accuracy: 0.0236 - val_loss: 4.6645 - val_accuracy: 0.0217 - lr: 1.0000e-04\n",
      "Epoch 118/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6540 - accuracy: 0.0243 - val_loss: 4.6703 - val_accuracy: 0.0228 - lr: 1.0000e-04\n",
      "Epoch 119/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6525 - accuracy: 0.0240 - val_loss: 4.6741 - val_accuracy: 0.0197 - lr: 1.0000e-04\n",
      "Epoch 120/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6510 - accuracy: 0.0241 - val_loss: 4.6627 - val_accuracy: 0.0216 - lr: 1.0000e-04\n",
      "Epoch 121/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6499 - accuracy: 0.0243 - val_loss: 4.6721 - val_accuracy: 0.0218 - lr: 1.0000e-04\n",
      "Epoch 122/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6479 - accuracy: 0.0238 - val_loss: 4.6583 - val_accuracy: 0.0220 - lr: 1.0000e-04\n",
      "Epoch 123/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6498 - accuracy: 0.0236 - val_loss: 4.6595 - val_accuracy: 0.0232 - lr: 1.0000e-04\n",
      "Epoch 124/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6487 - accuracy: 0.0240 - val_loss: 4.6584 - val_accuracy: 0.0218 - lr: 1.0000e-04\n",
      "Epoch 125/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6465 - accuracy: 0.0242 - val_loss: 4.6707 - val_accuracy: 0.0227 - lr: 1.0000e-04\n",
      "Epoch 126/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6454 - accuracy: 0.0238 - val_loss: 4.6575 - val_accuracy: 0.0222 - lr: 1.0000e-04\n",
      "Epoch 127/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6450 - accuracy: 0.0244 - val_loss: 4.6554 - val_accuracy: 0.0230 - lr: 1.0000e-04\n",
      "Epoch 128/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6451 - accuracy: 0.0245 - val_loss: 4.6583 - val_accuracy: 0.0218 - lr: 1.0000e-04\n",
      "Epoch 129/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6445 - accuracy: 0.0244 - val_loss: 4.6783 - val_accuracy: 0.0216 - lr: 1.0000e-04\n",
      "Epoch 130/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6406 - accuracy: 0.0241 - val_loss: 4.6526 - val_accuracy: 0.0232 - lr: 1.0000e-04\n",
      "Epoch 131/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6424 - accuracy: 0.0246 - val_loss: 4.6646 - val_accuracy: 0.0204 - lr: 1.0000e-04\n",
      "Epoch 132/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6397 - accuracy: 0.0247 - val_loss: 4.6719 - val_accuracy: 0.0238 - lr: 1.0000e-04\n",
      "Epoch 133/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6402 - accuracy: 0.0246 - val_loss: 4.7148 - val_accuracy: 0.0200 - lr: 1.0000e-04\n",
      "Epoch 134/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6396 - accuracy: 0.0247 - val_loss: 4.6530 - val_accuracy: 0.0227 - lr: 1.0000e-04\n",
      "Epoch 135/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6389 - accuracy: 0.0246 - val_loss: 4.6484 - val_accuracy: 0.0218 - lr: 1.0000e-04\n",
      "Epoch 136/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6366 - accuracy: 0.0251 - val_loss: 4.6490 - val_accuracy: 0.0258 - lr: 1.0000e-04\n",
      "Epoch 137/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6367 - accuracy: 0.0245 - val_loss: 4.6533 - val_accuracy: 0.0225 - lr: 1.0000e-04\n",
      "Epoch 138/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6355 - accuracy: 0.0248 - val_loss: 4.6463 - val_accuracy: 0.0232 - lr: 1.0000e-04\n",
      "Epoch 139/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6329 - accuracy: 0.0241 - val_loss: 4.6473 - val_accuracy: 0.0203 - lr: 1.0000e-04\n",
      "Epoch 140/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6355 - accuracy: 0.0248 - val_loss: 4.6540 - val_accuracy: 0.0214 - lr: 1.0000e-04\n",
      "Epoch 141/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6341 - accuracy: 0.0246 - val_loss: 4.6469 - val_accuracy: 0.0245 - lr: 1.0000e-04\n",
      "Epoch 142/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6312 - accuracy: 0.0246 - val_loss: 4.6530 - val_accuracy: 0.0239 - lr: 1.0000e-04\n",
      "Epoch 143/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6330 - accuracy: 0.0239 - val_loss: 4.6666 - val_accuracy: 0.0221 - lr: 1.0000e-04\n",
      "Epoch 144/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6296 - accuracy: 0.0253 - val_loss: 4.6419 - val_accuracy: 0.0227 - lr: 1.0000e-04\n",
      "Epoch 145/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6285 - accuracy: 0.0253 - val_loss: 4.6492 - val_accuracy: 0.0231 - lr: 1.0000e-04\n",
      "Epoch 146/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6297 - accuracy: 0.0244 - val_loss: 4.6571 - val_accuracy: 0.0244 - lr: 1.0000e-04\n",
      "Epoch 147/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6279 - accuracy: 0.0250 - val_loss: 4.6569 - val_accuracy: 0.0233 - lr: 1.0000e-04\n",
      "Epoch 148/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6263 - accuracy: 0.0256 - val_loss: 4.6393 - val_accuracy: 0.0228 - lr: 1.0000e-04\n",
      "Epoch 149/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6280 - accuracy: 0.0250 - val_loss: 4.6364 - val_accuracy: 0.0218 - lr: 1.0000e-04\n",
      "Epoch 150/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6247 - accuracy: 0.0254 - val_loss: 4.6460 - val_accuracy: 0.0230 - lr: 1.0000e-04\n",
      "Epoch 151/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6238 - accuracy: 0.0251 - val_loss: 4.6433 - val_accuracy: 0.0217 - lr: 1.0000e-04\n",
      "Epoch 152/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6245 - accuracy: 0.0247 - val_loss: 4.6363 - val_accuracy: 0.0254 - lr: 1.0000e-04\n",
      "Epoch 153/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6235 - accuracy: 0.0252 - val_loss: 4.6703 - val_accuracy: 0.0218 - lr: 1.0000e-04\n",
      "Epoch 154/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6218 - accuracy: 0.0252 - val_loss: 4.6342 - val_accuracy: 0.0219 - lr: 1.0000e-04\n",
      "Epoch 155/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6211 - accuracy: 0.0256 - val_loss: 4.6392 - val_accuracy: 0.0204 - lr: 1.0000e-04\n",
      "Epoch 156/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6206 - accuracy: 0.0254 - val_loss: 4.6401 - val_accuracy: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 157/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6186 - accuracy: 0.0251 - val_loss: 4.6451 - val_accuracy: 0.0226 - lr: 1.0000e-04\n",
      "Epoch 158/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6212 - accuracy: 0.0247 - val_loss: 4.6349 - val_accuracy: 0.0245 - lr: 1.0000e-04\n",
      "Epoch 159/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6174 - accuracy: 0.0251 - val_loss: 4.6375 - val_accuracy: 0.0228 - lr: 1.0000e-04\n",
      "Epoch 160/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6180 - accuracy: 0.0258 - val_loss: 4.6291 - val_accuracy: 0.0223 - lr: 1.0000e-04\n",
      "Epoch 161/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6172 - accuracy: 0.0251 - val_loss: 4.6336 - val_accuracy: 0.0231 - lr: 1.0000e-04\n",
      "Epoch 162/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6154 - accuracy: 0.0255 - val_loss: 4.6309 - val_accuracy: 0.0218 - lr: 1.0000e-04\n",
      "Epoch 163/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6142 - accuracy: 0.0251 - val_loss: 4.6278 - val_accuracy: 0.0240 - lr: 1.0000e-04\n",
      "Epoch 164/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6147 - accuracy: 0.0250 - val_loss: 4.6262 - val_accuracy: 0.0202 - lr: 1.0000e-04\n",
      "Epoch 165/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6137 - accuracy: 0.0249 - val_loss: 4.6414 - val_accuracy: 0.0240 - lr: 1.0000e-04\n",
      "Epoch 166/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6125 - accuracy: 0.0257 - val_loss: 4.6249 - val_accuracy: 0.0240 - lr: 1.0000e-04\n",
      "Epoch 167/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6096 - accuracy: 0.0257 - val_loss: 4.6268 - val_accuracy: 0.0247 - lr: 1.0000e-04\n",
      "Epoch 168/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6119 - accuracy: 0.0253 - val_loss: 4.6310 - val_accuracy: 0.0240 - lr: 1.0000e-04\n",
      "Epoch 169/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6131 - accuracy: 0.0252 - val_loss: 4.6235 - val_accuracy: 0.0229 - lr: 1.0000e-04\n",
      "Epoch 170/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6105 - accuracy: 0.0256 - val_loss: 4.6446 - val_accuracy: 0.0222 - lr: 1.0000e-04\n",
      "Epoch 171/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6078 - accuracy: 0.0261 - val_loss: 4.6340 - val_accuracy: 0.0218 - lr: 1.0000e-04\n",
      "Epoch 172/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6086 - accuracy: 0.0255 - val_loss: 4.6233 - val_accuracy: 0.0231 - lr: 1.0000e-04\n",
      "Epoch 173/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6069 - accuracy: 0.0260 - val_loss: 4.6629 - val_accuracy: 0.0224 - lr: 1.0000e-04\n",
      "Epoch 174/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6079 - accuracy: 0.0257 - val_loss: 4.6217 - val_accuracy: 0.0224 - lr: 1.0000e-04\n",
      "Epoch 175/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6057 - accuracy: 0.0258 - val_loss: 4.6228 - val_accuracy: 0.0250 - lr: 1.0000e-04\n",
      "Epoch 176/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6045 - accuracy: 0.0252 - val_loss: 4.6341 - val_accuracy: 0.0242 - lr: 1.0000e-04\n",
      "Epoch 177/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6041 - accuracy: 0.0257 - val_loss: 4.6245 - val_accuracy: 0.0231 - lr: 1.0000e-04\n",
      "Epoch 178/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6040 - accuracy: 0.0264 - val_loss: 4.6285 - val_accuracy: 0.0236 - lr: 1.0000e-04\n",
      "Epoch 179/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6056 - accuracy: 0.0254 - val_loss: 4.6204 - val_accuracy: 0.0225 - lr: 1.0000e-04\n",
      "Epoch 180/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6040 - accuracy: 0.0259 - val_loss: 4.6146 - val_accuracy: 0.0230 - lr: 1.0000e-04\n",
      "Epoch 181/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6011 - accuracy: 0.0253 - val_loss: 4.6137 - val_accuracy: 0.0238 - lr: 1.0000e-04\n",
      "Epoch 182/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6027 - accuracy: 0.0258 - val_loss: 4.6265 - val_accuracy: 0.0240 - lr: 1.0000e-04\n",
      "Epoch 183/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6009 - accuracy: 0.0256 - val_loss: 4.6198 - val_accuracy: 0.0234 - lr: 1.0000e-04\n",
      "Epoch 184/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.5994 - accuracy: 0.0262 - val_loss: 4.6121 - val_accuracy: 0.0218 - lr: 1.0000e-04\n",
      "Epoch 185/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.6010 - accuracy: 0.0253 - val_loss: 4.6846 - val_accuracy: 0.0194 - lr: 1.0000e-04\n",
      "Epoch 186/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.5997 - accuracy: 0.0261 - val_loss: 4.6205 - val_accuracy: 0.0237 - lr: 1.0000e-04\n",
      "Epoch 187/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.5985 - accuracy: 0.0255 - val_loss: 4.6117 - val_accuracy: 0.0233 - lr: 1.0000e-04\n",
      "Epoch 188/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.5977 - accuracy: 0.0257 - val_loss: 4.6110 - val_accuracy: 0.0240 - lr: 1.0000e-04\n",
      "Epoch 189/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.5997 - accuracy: 0.0258 - val_loss: 4.6411 - val_accuracy: 0.0213 - lr: 1.0000e-04\n",
      "Epoch 190/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.5967 - accuracy: 0.0253 - val_loss: 4.6202 - val_accuracy: 0.0237 - lr: 1.0000e-04\n",
      "Epoch 191/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.5974 - accuracy: 0.0252 - val_loss: 4.6474 - val_accuracy: 0.0242 - lr: 1.0000e-04\n",
      "Epoch 192/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.5967 - accuracy: 0.0263 - val_loss: 4.6562 - val_accuracy: 0.0238 - lr: 1.0000e-04\n",
      "Epoch 193/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.5969 - accuracy: 0.0260 - val_loss: 4.6100 - val_accuracy: 0.0230 - lr: 1.0000e-04\n",
      "Epoch 194/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.5936 - accuracy: 0.0264 - val_loss: 4.6073 - val_accuracy: 0.0245 - lr: 1.0000e-04\n",
      "Epoch 195/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.5928 - accuracy: 0.0262 - val_loss: 4.6086 - val_accuracy: 0.0263 - lr: 1.0000e-04\n",
      "Epoch 196/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.5957 - accuracy: 0.0262 - val_loss: 4.6075 - val_accuracy: 0.0232 - lr: 1.0000e-04\n",
      "Epoch 197/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.5910 - accuracy: 0.0259 - val_loss: 4.6081 - val_accuracy: 0.0252 - lr: 1.0000e-04\n",
      "Epoch 198/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.5945 - accuracy: 0.0258 - val_loss: 4.6104 - val_accuracy: 0.0221 - lr: 1.0000e-04\n",
      "Epoch 199/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.5930 - accuracy: 0.0263 - val_loss: 4.6121 - val_accuracy: 0.0235 - lr: 1.0000e-04\n",
      "Epoch 200/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.5908 - accuracy: 0.0262 - val_loss: 4.6039 - val_accuracy: 0.0259 - lr: 1.0000e-04\n",
      "Epoch 201/300\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 4.5922 - accuracy: 0.0262 - val_loss: 4.6147 - val_accuracy: 0.0225 - lr: 1.0000e-04\n",
      "Epoch 202/300\n",
      "656/704 [==========================>...] - ETA: 0s - loss: 4.5895 - accuracy: 0.0257"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m x_val, y_val, _, _ \u001b[38;5;241m=\u001b[39m val_data\n\u001b[1;32m     26\u001b[0m model \u001b[38;5;241m=\u001b[39m CNN_images(HP, CNN_INPUT_SHAPE)\n\u001b[0;32m---> 28\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHP\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhistory\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Retrieve test data here in order to always have random data\u001b[39;00m\n\u001b[1;32m     39\u001b[0m test_dl \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     40\u001b[0m     TEST_CONFIG, \n\u001b[1;32m     41\u001b[0m     \u001b[38;5;241m5000\u001b[39m,\n\u001b[1;32m     42\u001b[0m     byte_idx\u001b[38;5;241m=\u001b[39mBYTE_IDX, \n\u001b[1;32m     43\u001b[0m     target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSBOX_OUT\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     44\u001b[0m )\n",
      "File \u001b[0;32m~/MDM32/mdm32_env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/MDM32/mdm32_env/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/MDM32/mdm32_env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/MDM32/mdm32_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/MDM32/mdm32_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/MDM32/mdm32_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MDM32/mdm32_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/MDM32/mdm32_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/MDM32/mdm32_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BYTE_IDX = 0\n",
    "MAX_N_KEYS = 10\n",
    "TEST_CONFIG = ['D3-K0']\n",
    "TOT_TRACES = 100000\n",
    "# CNN_INPUT_SHAPE = (1183, 1)\n",
    "CNN_INPUT_SHAPE = (64, 64, 1)\n",
    "\n",
    "\n",
    "for N_KEYS in range(10, MAX_N_KEYS+1):\n",
    "    \n",
    "    TRAIN_DEVS = ['D1', 'D2']\n",
    "    TRAIN_CONFIGS = [f'{dev}-K{k}' for k in range(1, N_KEYS+1) for dev in TRAIN_DEVS]\n",
    "\n",
    "    train_dl = SplitDataLoader(\n",
    "        TRAIN_CONFIGS, \n",
    "        TOT_TRACES, \n",
    "        train_size=0.9,\n",
    "        byte_idx=BYTE_IDX, \n",
    "        target='SBOX_OUT'\n",
    "    )\n",
    "    train_data, val_data = train_dl.load()\n",
    "    x_train, y_train, _, _ = train_data\n",
    "    x_val, y_val, _, _ = val_data\n",
    "\n",
    "\n",
    "    model = CNN_images(HP, CNN_INPUT_SHAPE)\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train, \n",
    "        y_train, \n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=300,\n",
    "        batch_size=HP['batch_size'],\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    ).history\n",
    "    \n",
    "    # Retrieve test data here in order to always have random data\n",
    "    test_dl = DataLoader(\n",
    "        TEST_CONFIG, \n",
    "        5000,\n",
    "        byte_idx=BYTE_IDX, \n",
    "        target='SBOX_OUT'\n",
    "    )\n",
    "    x_test, y_test, pltxts_test, tkbs_test = test_dl.load()\n",
    "    \n",
    "    test_preds = model.predict(x_test)\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f'test_loss = {test_loss}')\n",
    "    print(f'test_acc = {test_acc}')\n",
    "    \n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c4c5f5-d029-4301-9b7b-6759a353057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history['loss'], label='train_loss')\n",
    "plt.plot(history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2a04b4-c68a-4934-b47c-02b18297b741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdm32_env",
   "language": "python",
   "name": "mdm32_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
