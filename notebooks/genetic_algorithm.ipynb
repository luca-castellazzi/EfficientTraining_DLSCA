{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7beb8ec-7ead-4e92-84be-6b6042c3e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TensorFlow/Keras (Keras layers below)\n",
    "from tensorflow.keras.utils import set_random_seed, to_categorical\n",
    "set_random_seed(1234) # set the seeds for Python, NumPy, and TensorFlow in order to reproduce the results\n",
    "\n",
    "# Custom\n",
    "import sys\n",
    "sys.path.insert(0, '/home/lcastellazzi/MDM32/src/utils')\n",
    "from preprocessing import TraceHandler\n",
    "from nicv import nicv\n",
    "import constants\n",
    "from postprocessing import SingleByteEvaluator\n",
    "\n",
    "\n",
    "# Suppress TensorFlow messages\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' # 1 for INFO, 2 for INFO & WARNINGs, 3 for INFO & WARNINGs & ERRORs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcff22a6-1b26-436b-b06a-99da13a4b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import constants\n",
    "\n",
    "\n",
    "def create_callbacks(es=True): # In future also other callbacks, for example the one to same the model in .h5 file\n",
    "    callbacks = []\n",
    "    \n",
    "    if es:\n",
    "        callbacks.append(EarlyStopping(monitor='val_loss', patience=5))\n",
    "        \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90697664-fbdf-4f4d-a5e2-a2da737e5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "# from network_helpers import build_model, train_and_val_model, evaluate_model\n",
    "\n",
    "\n",
    "class Network():\n",
    "    \n",
    "    def __init__(self, model_type, hp_choices):\n",
    "        self._model_type = model_type\n",
    "        self._hp_choices = hp_choices\n",
    "        self._hp = {}\n",
    "        self._model = Sequential()\n",
    "\n",
    "    \n",
    "    def get_hp(self, hp_name):\n",
    "        return self._hp[hp_name]\n",
    "    \n",
    "    \n",
    "    def set_hp(self, hp):\n",
    "        self._hp = hp\n",
    "        \n",
    "        \n",
    "    def select_random_hp(self):\n",
    "        for hp_name in self._hp_choices:\n",
    "            self._hp[hp_name] = random.choice(self._hp_choices[hp_name])\n",
    "    \n",
    "    \n",
    "    def build_model(self):\n",
    "        if self._model_type == 'MLP':\n",
    "            # Input\n",
    "            self._model.add(Dense(constants.TRACE_LEN, \n",
    "                            kernel_initializer=self._hp['kernel_initializer'], \n",
    "                            activation=self._hp['activation']))\n",
    "\n",
    "            # First BatchNorm\n",
    "            self._model.add(BatchNormalization())\n",
    "\n",
    "            # Hidden\n",
    "            for _ in range(self._hp['hidden_layers']):\n",
    "                self._model.add(Dense(self._hp['hidden_neurons'], \n",
    "                                kernel_initializer=self._hp['kernel_initializer'], \n",
    "                                activation=self._hp['activation']))\n",
    "\n",
    "                # Dropout\n",
    "                self._model.add(Dropout(self._hp['dropout_rate']))\n",
    "\n",
    "            # Second BatchNorm\n",
    "            self._model.add(BatchNormalization())\n",
    "\n",
    "            # Output\n",
    "            self._model.add(Dense(256, activation='softmax')) ########################### 256 to be changed if the target is changed (HW, ...)\n",
    "\n",
    "            # Compilation\n",
    "            self._model.compile(optimizer=self._hp['optimizer'](learning_rate=self._hp['learning_rate']),\n",
    "                                loss='categorical_crossentropy',\n",
    "                                metrics=['accuracy'])\n",
    "        else:\n",
    "            pass # In future there will be CNN\n",
    "    \n",
    "    \n",
    "    def train_and_val(self, x_train, y_train, x_val, y_val):\n",
    "        callbacks = create_callbacks()\n",
    "    \n",
    "        # Default train and validation (w.r.t accuracy)\n",
    "        self._model.fit(x_train, \n",
    "                        y_train,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        epochs=100, # maybe as hp?\n",
    "                        batch_size=100, # maybe as hp?\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=1)\n",
    "        \n",
    "        # Evaluation of the model over the val data in order to have the overal val-performance (w.r.t. accuracy) \n",
    "        val_loss, val_acc = self._model.evaluate(x_val, \n",
    "                                                 y_val, \n",
    "                                                 verbose=0)\n",
    "        return val_acc\n",
    "    \n",
    "    \n",
    "    def final_train(self, x_train_tot, y_train_tot):\n",
    "        \n",
    "        # Default train and validation (w.r.t accuracy)\n",
    "        self._model.fit(x_train_tot, \n",
    "                        y_train_tot,\n",
    "                        epochs=100, # maybe as hp?\n",
    "                        batch_size=100, # maybe as hp?\n",
    "                        verbose=1)\n",
    "        \n",
    "    \n",
    "    def plot_guessing_entropy(self, x_test, y_test, test_plaintexts, true_key_byte, byte_idx, n_exp=10):\n",
    "        traces_per_exp = int(len(x_test) / n_exp)\n",
    "        \n",
    "        test_accs = []\n",
    "        ranks = []\n",
    "        for i in range(n_exp):\n",
    "            start = i * traces_per_exp\n",
    "            end = start + traces_per_exp\n",
    "\n",
    "            test_loss, test_acc = self._model.evaluate(x_test, y_test, verbose=1)\n",
    "            test_accs.append(test_acc)\n",
    "            \n",
    "            curr_preds = self._model.predict(x_test[start:end])\n",
    "\n",
    "            curr_plaintexts = test_plaintexts[start:end]\n",
    "            curr_evaluator = SingleByteEvaluator(test_plaintexts=curr_plaintexts,\n",
    "                                                 byte_idx=byte_idx,\n",
    "                                                 label_preds=curr_preds)\n",
    "            curr_ranks = []\n",
    "            for j in tqdm(range(traces_per_exp)):\n",
    "                n_traces = j + 1\n",
    "                curr_ranks.append(curr_evaluator.rank(true_key_byte, n_traces))\n",
    "\n",
    "            curr_ranks = np.array(curr_ranks)\n",
    "            ranks.append(curr_ranks)\n",
    "\n",
    "        test_accs = np.array(test_accs)\n",
    "        ranks = np.array(ranks)\n",
    "\n",
    "        guessing_entropy = np.round(np.mean(ranks, axis=0)) # .5 approximated to the next int\n",
    "\n",
    "        f, ax = plt.subplots(2, 1, figsize=(10, 15))\n",
    "        \n",
    "        ax[0].plot(test_accs, color='r')\n",
    "        ax[0].set_title('Test acc')\n",
    "        ax[0].grid()\n",
    "        \n",
    "        ax[1].plot(guessing_entropy[:50], color='b', marker='o')\n",
    "        ax[1].set_title('Guessing Entropy')\n",
    "        ax[1].grid()\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b11e7663-a602-409a-b865-e1ad7c8a308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class GeneticTuner():\n",
    "    \n",
    "    def __init__(self, hp_choices, model_type='MLP', pop_size=10, selection_perc=0.5, mutation_chance=0.2):\n",
    "        self._model_type = model_type\n",
    "        self._pop_size = pop_size\n",
    "        self._hp_choices = hp_choices\n",
    "        self._selection_perc = selection_perc\n",
    "        self._mutation_chance = mutation_chance\n",
    "    \n",
    "    \n",
    "    def populate(self):\n",
    "        pop = []\n",
    "        for _ in range(self._pop_size):\n",
    "            individual = Network(self._model_type, self._hp_choices)\n",
    "            individual.select_random_hp()\n",
    "            pop.append(individual)\n",
    "            \n",
    "        return pop\n",
    "    \n",
    "        \n",
    "    def evaluate(self, pop, x_train, y_train, x_val, y_val):\n",
    "        \n",
    "        fitness_values = []\n",
    "        for i, individual in enumerate(pop):\n",
    "            print()\n",
    "            print(f'***** Individual {i+1}/{self._pop_size} *****')\n",
    "            \n",
    "            individual.build_model()\n",
    "            val_acc = individual.train_and_val(x_train, y_train, x_val, y_val) # Default train and val w.r.t. accuracy\n",
    "            fitness_values.append(val_acc) \n",
    "        \n",
    "        evaluation = list(zip(pop, fitness_values))\n",
    "        \n",
    "        return evaluation\n",
    "    \n",
    "    \n",
    "    def select(self, evaluation):\n",
    "        num_selected = int(self._selection_perc * self._pop_size)\n",
    "        evaluation.sort(key=lambda x: -x[1]) # Sort the individuals w.r.t. their accuracy (the higher the better, so the \"-\" is needed)\n",
    "        sorted_pop = [individual for individual, _ in evaluation]\n",
    "        parents = sorted_pop[:num_selected]\n",
    "        \n",
    "        return parents\n",
    "        \n",
    "    \n",
    "    def _produce_offspring(self, parentA, parentB):\n",
    "        # An offspring contains hps from both parents (random selection)\n",
    "        offspring_hp = {hp_name: random.choice([parentA.get_hp(hp_name), parentA.get_hp(hp_name)]) \n",
    "                        for hp_name in self._hp_choices}\n",
    "        \n",
    "        return offspring_hp\n",
    "        \n",
    "    \n",
    "    def _mutate_offspring(self, offspring_hp):\n",
    "        # A mutation is a random hp from the possible choices\n",
    "        to_mutate = random.choice(list(self._hp_choices.keys()))\n",
    "        offspring_hp[to_mutate] = random.choice(self._hp_choices[to_mutate])\n",
    "        \n",
    "        return offspring_hp\n",
    "    \n",
    "    \n",
    "    def evolve(self, parents):\n",
    "        # Only the individuals with the best performances are kept and used to generate offsprings\n",
    "        # The size of the population is the same\n",
    "        num_offsprings = self._pop_size - len(parents)\n",
    "        \n",
    "        offsprings = []\n",
    "        for _ in range(num_offsprings):\n",
    "            parentA, parentB = random.sample(parents, k=2)\n",
    "            offspring_hp = self._produce_offspring(parentA, parentB)\n",
    "            \n",
    "            if self._mutation_chance > random.random():\n",
    "                offspring_hp = self._mutate_offspring(offspring_hp)\n",
    "            \n",
    "            offspring = Network(self._model_type, self._hp_choices)\n",
    "            offspring.set_hp(offspring_hp)\n",
    "            \n",
    "            offsprings.append(offspring)\n",
    "            \n",
    "        new_pop = parents + offsprings\n",
    "        \n",
    "        return new_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688c3654-9c4f-48e0-96a3-4cd99ed5b471",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd9523e-0256-4a59-9fcd-0d332183f05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling traces: 100%|██████████| 50000/50000 [00:21<00:00, 2301.58it/s]\n"
     ]
    }
   ],
   "source": [
    "train_th = TraceHandler('/prj/side_channel/PinataTraces/CURR/D1-K1_50k_500MHz + Resampled at 168MHz.trs')\n",
    "\n",
    "BYTE_IDX = 0\n",
    "N_CLASSES = 256\n",
    "VAL_PERC = 0.1\n",
    "\n",
    "x_train_tot = train_th.get_traces()\n",
    "y_train_tot = train_th.get_specific_labels(BYTE_IDX)\n",
    "y_train_tot = to_categorical(y_train_tot, N_CLASSES)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_th.generate_train_val(BYTE_IDX, val_perc=VAL_PERC)\n",
    "y_train = to_categorical(y_train, N_CLASSES)\n",
    "y_val = to_categorical(y_val, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80738193-c727-4d28-a9e3-285104b0e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "HP_CHOICES = {'kernel_initializer': ['random_normal', 'he_normal'],\n",
    "              'activation':         ['relu', 'tanh'],\n",
    "              'hidden_layers':      [1, 2, 3, 4, 5],\n",
    "              'hidden_neurons':     [100, 200, 300, 400, 500],\n",
    "              'dropout_rate':       [0.0, 0.2, 0.4],\n",
    "              'optimizer':          [Adam, RMSprop],\n",
    "              'learning_rate':      [1e-3, 1e-4, 1e-5]}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c13db7fe-e678-41e3-86c6-b385e6e59919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- Generation 1/2 --------------------\n",
      "\n",
      "***** Individual 1/6 *****\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.8055 - accuracy: 0.0044 - val_loss: 5.6721 - val_accuracy: 0.0048\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.7645 - accuracy: 0.0052 - val_loss: 5.6583 - val_accuracy: 0.0040\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.7286 - accuracy: 0.0052 - val_loss: 5.6286 - val_accuracy: 0.0070\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.7005 - accuracy: 0.0055 - val_loss: 5.6086 - val_accuracy: 0.0062\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.6661 - accuracy: 0.0069 - val_loss: 5.5813 - val_accuracy: 0.0072\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.6377 - accuracy: 0.0083 - val_loss: 5.5572 - val_accuracy: 0.0072\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.6049 - accuracy: 0.0084 - val_loss: 5.5326 - val_accuracy: 0.0080\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5842 - accuracy: 0.0092 - val_loss: 5.5007 - val_accuracy: 0.0072\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5588 - accuracy: 0.0097 - val_loss: 5.4771 - val_accuracy: 0.0074\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5324 - accuracy: 0.0101 - val_loss: 5.4569 - val_accuracy: 0.0094\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5174 - accuracy: 0.0106 - val_loss: 5.4412 - val_accuracy: 0.0084\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4909 - accuracy: 0.0115 - val_loss: 5.4243 - val_accuracy: 0.0092\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4711 - accuracy: 0.0120 - val_loss: 5.4096 - val_accuracy: 0.0092\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4540 - accuracy: 0.0116 - val_loss: 5.3909 - val_accuracy: 0.0102\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4353 - accuracy: 0.0124 - val_loss: 5.3759 - val_accuracy: 0.0086\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4155 - accuracy: 0.0137 - val_loss: 5.3617 - val_accuracy: 0.0104\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4000 - accuracy: 0.0133 - val_loss: 5.3476 - val_accuracy: 0.0100\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3783 - accuracy: 0.0142 - val_loss: 5.3254 - val_accuracy: 0.0100\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3595 - accuracy: 0.0130 - val_loss: 5.3167 - val_accuracy: 0.0124\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3470 - accuracy: 0.0142 - val_loss: 5.3005 - val_accuracy: 0.0122\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3305 - accuracy: 0.0151 - val_loss: 5.2879 - val_accuracy: 0.0130\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3157 - accuracy: 0.0161 - val_loss: 5.2707 - val_accuracy: 0.0142\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2916 - accuracy: 0.0159 - val_loss: 5.2558 - val_accuracy: 0.0134\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2798 - accuracy: 0.0174 - val_loss: 5.2379 - val_accuracy: 0.0154\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2663 - accuracy: 0.0179 - val_loss: 5.2232 - val_accuracy: 0.0148\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2463 - accuracy: 0.0184 - val_loss: 5.2130 - val_accuracy: 0.0162\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2315 - accuracy: 0.0188 - val_loss: 5.1930 - val_accuracy: 0.0186\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2128 - accuracy: 0.0214 - val_loss: 5.1867 - val_accuracy: 0.0162\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2007 - accuracy: 0.0189 - val_loss: 5.1697 - val_accuracy: 0.0186\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1858 - accuracy: 0.0217 - val_loss: 5.1525 - val_accuracy: 0.0194\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1658 - accuracy: 0.0215 - val_loss: 5.1379 - val_accuracy: 0.0218\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1489 - accuracy: 0.0222 - val_loss: 5.1261 - val_accuracy: 0.0198\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1385 - accuracy: 0.0232 - val_loss: 5.1084 - val_accuracy: 0.0222\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1229 - accuracy: 0.0242 - val_loss: 5.0996 - val_accuracy: 0.0250\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1088 - accuracy: 0.0241 - val_loss: 5.0828 - val_accuracy: 0.0234\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0971 - accuracy: 0.0260 - val_loss: 5.0679 - val_accuracy: 0.0228\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0790 - accuracy: 0.0259 - val_loss: 5.0563 - val_accuracy: 0.0228\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0698 - accuracy: 0.0248 - val_loss: 5.0460 - val_accuracy: 0.0244\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0555 - accuracy: 0.0285 - val_loss: 5.0397 - val_accuracy: 0.0244\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0460 - accuracy: 0.0292 - val_loss: 5.0230 - val_accuracy: 0.0248\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0256 - accuracy: 0.0288 - val_loss: 5.0089 - val_accuracy: 0.0262\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0195 - accuracy: 0.0287 - val_loss: 4.9981 - val_accuracy: 0.0278\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0068 - accuracy: 0.0314 - val_loss: 4.9914 - val_accuracy: 0.0282\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9965 - accuracy: 0.0306 - val_loss: 4.9753 - val_accuracy: 0.0248\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9830 - accuracy: 0.0303 - val_loss: 4.9670 - val_accuracy: 0.0266\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9754 - accuracy: 0.0314 - val_loss: 4.9525 - val_accuracy: 0.0266\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9602 - accuracy: 0.0318 - val_loss: 4.9471 - val_accuracy: 0.0296\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9475 - accuracy: 0.0317 - val_loss: 4.9347 - val_accuracy: 0.0300\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9426 - accuracy: 0.0323 - val_loss: 4.9205 - val_accuracy: 0.0310\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9293 - accuracy: 0.0330 - val_loss: 4.9152 - val_accuracy: 0.0306\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9173 - accuracy: 0.0338 - val_loss: 4.9097 - val_accuracy: 0.0316\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9102 - accuracy: 0.0335 - val_loss: 4.9016 - val_accuracy: 0.0318\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9054 - accuracy: 0.0349 - val_loss: 4.8911 - val_accuracy: 0.0312\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8922 - accuracy: 0.0366 - val_loss: 4.8845 - val_accuracy: 0.0320\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8825 - accuracy: 0.0350 - val_loss: 4.8729 - val_accuracy: 0.0324\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8752 - accuracy: 0.0357 - val_loss: 4.8681 - val_accuracy: 0.0346\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8610 - accuracy: 0.0364 - val_loss: 4.8565 - val_accuracy: 0.0356\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8554 - accuracy: 0.0369 - val_loss: 4.8539 - val_accuracy: 0.0354\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8444 - accuracy: 0.0362 - val_loss: 4.8500 - val_accuracy: 0.0372\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8405 - accuracy: 0.0387 - val_loss: 4.8423 - val_accuracy: 0.0342\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8252 - accuracy: 0.0383 - val_loss: 4.8304 - val_accuracy: 0.0342\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8223 - accuracy: 0.0370 - val_loss: 4.8258 - val_accuracy: 0.0338\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8181 - accuracy: 0.0372 - val_loss: 4.8088 - val_accuracy: 0.0362\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8104 - accuracy: 0.0365 - val_loss: 4.8101 - val_accuracy: 0.0352\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7983 - accuracy: 0.0379 - val_loss: 4.8002 - val_accuracy: 0.0366\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7944 - accuracy: 0.0393 - val_loss: 4.8006 - val_accuracy: 0.0376\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7898 - accuracy: 0.0393 - val_loss: 4.7843 - val_accuracy: 0.0370\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7807 - accuracy: 0.0409 - val_loss: 4.7839 - val_accuracy: 0.0374\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7691 - accuracy: 0.0415 - val_loss: 4.7780 - val_accuracy: 0.0390\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7635 - accuracy: 0.0418 - val_loss: 4.7658 - val_accuracy: 0.0380\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7589 - accuracy: 0.0411 - val_loss: 4.7677 - val_accuracy: 0.0370\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7526 - accuracy: 0.0408 - val_loss: 4.7674 - val_accuracy: 0.0366\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7473 - accuracy: 0.0422 - val_loss: 4.7590 - val_accuracy: 0.0388\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7356 - accuracy: 0.0429 - val_loss: 4.7531 - val_accuracy: 0.0390\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7309 - accuracy: 0.0434 - val_loss: 4.7488 - val_accuracy: 0.0392\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7255 - accuracy: 0.0437 - val_loss: 4.7444 - val_accuracy: 0.0380\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7163 - accuracy: 0.0438 - val_loss: 4.7313 - val_accuracy: 0.0402\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7115 - accuracy: 0.0446 - val_loss: 4.7326 - val_accuracy: 0.0368\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7060 - accuracy: 0.0438 - val_loss: 4.7305 - val_accuracy: 0.0400\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7010 - accuracy: 0.0449 - val_loss: 4.7142 - val_accuracy: 0.0380\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6948 - accuracy: 0.0453 - val_loss: 4.7094 - val_accuracy: 0.0400\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6903 - accuracy: 0.0455 - val_loss: 4.7038 - val_accuracy: 0.0408\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6780 - accuracy: 0.0450 - val_loss: 4.7130 - val_accuracy: 0.0412\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6765 - accuracy: 0.0483 - val_loss: 4.7084 - val_accuracy: 0.0400\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6716 - accuracy: 0.0467 - val_loss: 4.6989 - val_accuracy: 0.0396\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6616 - accuracy: 0.0481 - val_loss: 4.6994 - val_accuracy: 0.0424\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6571 - accuracy: 0.0477 - val_loss: 4.7071 - val_accuracy: 0.0440\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6553 - accuracy: 0.0476 - val_loss: 4.6806 - val_accuracy: 0.0416\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6489 - accuracy: 0.0501 - val_loss: 4.6793 - val_accuracy: 0.0456\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6438 - accuracy: 0.0478 - val_loss: 4.6726 - val_accuracy: 0.0438\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6358 - accuracy: 0.0498 - val_loss: 4.6742 - val_accuracy: 0.0414\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6267 - accuracy: 0.0516 - val_loss: 4.6709 - val_accuracy: 0.0410\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6215 - accuracy: 0.0515 - val_loss: 4.6647 - val_accuracy: 0.0464\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6185 - accuracy: 0.0509 - val_loss: 4.6655 - val_accuracy: 0.0424\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6170 - accuracy: 0.0508 - val_loss: 4.6496 - val_accuracy: 0.0442\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6061 - accuracy: 0.0518 - val_loss: 4.6533 - val_accuracy: 0.0428\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6027 - accuracy: 0.0516 - val_loss: 4.6479 - val_accuracy: 0.0452\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6003 - accuracy: 0.0526 - val_loss: 4.6498 - val_accuracy: 0.0420\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5928 - accuracy: 0.0513 - val_loss: 4.6332 - val_accuracy: 0.0448\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5927 - accuracy: 0.0530 - val_loss: 4.6293 - val_accuracy: 0.0436\n",
      "\n",
      "***** Individual 2/6 *****\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0554 - accuracy: 0.0214 - val_loss: 5.9442 - val_accuracy: 0.0174\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4372 - accuracy: 0.0498 - val_loss: 6.9890 - val_accuracy: 0.0134\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.1755 - accuracy: 0.0665 - val_loss: 4.6693 - val_accuracy: 0.0424\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.9871 - accuracy: 0.0806 - val_loss: 4.5814 - val_accuracy: 0.0492\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.8515 - accuracy: 0.0915 - val_loss: 5.1839 - val_accuracy: 0.0434\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.7539 - accuracy: 0.1036 - val_loss: 5.1244 - val_accuracy: 0.0418\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.6738 - accuracy: 0.1148 - val_loss: 4.1960 - val_accuracy: 0.0732\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.5938 - accuracy: 0.1257 - val_loss: 4.8366 - val_accuracy: 0.0460\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.5226 - accuracy: 0.1322 - val_loss: 5.0844 - val_accuracy: 0.0414\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.4546 - accuracy: 0.1456 - val_loss: 5.4228 - val_accuracy: 0.0404\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.4038 - accuracy: 0.1525 - val_loss: 4.3864 - val_accuracy: 0.0650\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.3408 - accuracy: 0.1637 - val_loss: 4.4550 - val_accuracy: 0.0680\n",
      "\n",
      "***** Individual 3/6 *****\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5941 - accuracy: 0.0038 - val_loss: 6.1662 - val_accuracy: 0.0048\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5450 - accuracy: 0.0040 - val_loss: 9.8812 - val_accuracy: 0.0030\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5449 - accuracy: 0.0039 - val_loss: 5.5478 - val_accuracy: 0.0030\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5448 - accuracy: 0.0048 - val_loss: 5.5477 - val_accuracy: 0.0038\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5447 - accuracy: 0.0043 - val_loss: 5.5472 - val_accuracy: 0.0038\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5447 - accuracy: 0.0043 - val_loss: 5.5474 - val_accuracy: 0.0038\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5446 - accuracy: 0.0048 - val_loss: 5.5473 - val_accuracy: 0.0038\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5446 - accuracy: 0.0043 - val_loss: 5.5473 - val_accuracy: 0.0038\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5444 - accuracy: 0.0047 - val_loss: 5.5480 - val_accuracy: 0.0030\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5445 - accuracy: 0.0041 - val_loss: 5.5481 - val_accuracy: 0.0030\n",
      "\n",
      "***** Individual 4/6 *****\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.9533 - accuracy: 0.0038 - val_loss: 5.8172 - val_accuracy: 0.0072\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.8003 - accuracy: 0.0054 - val_loss: 5.8883 - val_accuracy: 0.0064\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.6835 - accuracy: 0.0079 - val_loss: 5.7950 - val_accuracy: 0.0076\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5679 - accuracy: 0.0105 - val_loss: 5.7189 - val_accuracy: 0.0096\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4646 - accuracy: 0.0125 - val_loss: 5.6343 - val_accuracy: 0.0106\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3868 - accuracy: 0.0141 - val_loss: 5.5663 - val_accuracy: 0.0094\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3182 - accuracy: 0.0164 - val_loss: 5.5303 - val_accuracy: 0.0102\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2549 - accuracy: 0.0187 - val_loss: 5.4659 - val_accuracy: 0.0110\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1958 - accuracy: 0.0235 - val_loss: 5.4326 - val_accuracy: 0.0096\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1400 - accuracy: 0.0258 - val_loss: 5.3911 - val_accuracy: 0.0126\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0861 - accuracy: 0.0294 - val_loss: 5.3532 - val_accuracy: 0.0144\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0285 - accuracy: 0.0322 - val_loss: 5.3100 - val_accuracy: 0.0144\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9788 - accuracy: 0.0381 - val_loss: 5.2899 - val_accuracy: 0.0174\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9279 - accuracy: 0.0414 - val_loss: 5.2545 - val_accuracy: 0.0178\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8749 - accuracy: 0.0438 - val_loss: 5.2091 - val_accuracy: 0.0210\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8264 - accuracy: 0.0485 - val_loss: 5.1974 - val_accuracy: 0.0246\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7749 - accuracy: 0.0534 - val_loss: 5.1370 - val_accuracy: 0.0230\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7336 - accuracy: 0.0559 - val_loss: 5.1063 - val_accuracy: 0.0252\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6848 - accuracy: 0.0630 - val_loss: 5.0806 - val_accuracy: 0.0260\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6422 - accuracy: 0.0658 - val_loss: 5.0640 - val_accuracy: 0.0266\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6006 - accuracy: 0.0696 - val_loss: 5.0385 - val_accuracy: 0.0272\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5595 - accuracy: 0.0747 - val_loss: 5.0075 - val_accuracy: 0.0288\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5219 - accuracy: 0.0793 - val_loss: 4.9918 - val_accuracy: 0.0288\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4828 - accuracy: 0.0848 - val_loss: 4.9964 - val_accuracy: 0.0288\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4492 - accuracy: 0.0879 - val_loss: 4.9621 - val_accuracy: 0.0292\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4110 - accuracy: 0.0911 - val_loss: 4.9406 - val_accuracy: 0.0332\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3798 - accuracy: 0.0971 - val_loss: 4.9307 - val_accuracy: 0.0304\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3441 - accuracy: 0.1006 - val_loss: 4.9157 - val_accuracy: 0.0338\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3121 - accuracy: 0.1053 - val_loss: 4.9084 - val_accuracy: 0.0336\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.2842 - accuracy: 0.1092 - val_loss: 4.8948 - val_accuracy: 0.0316\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.2508 - accuracy: 0.1140 - val_loss: 4.9029 - val_accuracy: 0.0340\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.2201 - accuracy: 0.1193 - val_loss: 4.8801 - val_accuracy: 0.0296\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.1874 - accuracy: 0.1256 - val_loss: 4.8689 - val_accuracy: 0.0328\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.1622 - accuracy: 0.1294 - val_loss: 4.8717 - val_accuracy: 0.0322\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.1310 - accuracy: 0.1348 - val_loss: 4.8557 - val_accuracy: 0.0318\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.1029 - accuracy: 0.1371 - val_loss: 4.8613 - val_accuracy: 0.0360\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.0760 - accuracy: 0.1417 - val_loss: 4.8520 - val_accuracy: 0.0334\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.0489 - accuracy: 0.1460 - val_loss: 4.8454 - val_accuracy: 0.0328\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.0200 - accuracy: 0.1502 - val_loss: 4.8329 - val_accuracy: 0.0358\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.9954 - accuracy: 0.1571 - val_loss: 4.8353 - val_accuracy: 0.0350\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.9659 - accuracy: 0.1600 - val_loss: 4.8492 - val_accuracy: 0.0348\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.9379 - accuracy: 0.1688 - val_loss: 4.8367 - val_accuracy: 0.0316\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.9120 - accuracy: 0.1703 - val_loss: 4.8333 - val_accuracy: 0.0364\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.8892 - accuracy: 0.1719 - val_loss: 4.8265 - val_accuracy: 0.0342\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.8645 - accuracy: 0.1792 - val_loss: 4.8317 - val_accuracy: 0.0346\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.8347 - accuracy: 0.1834 - val_loss: 4.8231 - val_accuracy: 0.0336\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.8111 - accuracy: 0.1898 - val_loss: 4.8137 - val_accuracy: 0.0326\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.7848 - accuracy: 0.1945 - val_loss: 4.8106 - val_accuracy: 0.0382\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.7571 - accuracy: 0.2008 - val_loss: 4.8141 - val_accuracy: 0.0352\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.7367 - accuracy: 0.2022 - val_loss: 4.8123 - val_accuracy: 0.0366\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.7111 - accuracy: 0.2087 - val_loss: 4.8205 - val_accuracy: 0.0338\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.6873 - accuracy: 0.2104 - val_loss: 4.8058 - val_accuracy: 0.0356\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.6643 - accuracy: 0.2187 - val_loss: 4.8063 - val_accuracy: 0.0380\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.6383 - accuracy: 0.2216 - val_loss: 4.8086 - val_accuracy: 0.0378\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.6111 - accuracy: 0.2265 - val_loss: 4.8111 - val_accuracy: 0.0380\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.5898 - accuracy: 0.2322 - val_loss: 4.8139 - val_accuracy: 0.0370\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.5639 - accuracy: 0.2358 - val_loss: 4.8361 - val_accuracy: 0.0380\n",
      "\n",
      "***** Individual 5/6 *****\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.8034 - accuracy: 0.0041 - val_loss: 5.5668 - val_accuracy: 0.0030\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.7677 - accuracy: 0.0040 - val_loss: 5.5584 - val_accuracy: 0.0052\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.7347 - accuracy: 0.0041 - val_loss: 5.5479 - val_accuracy: 0.0066\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.7035 - accuracy: 0.0050 - val_loss: 5.5323 - val_accuracy: 0.0066\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.6604 - accuracy: 0.0064 - val_loss: 5.5082 - val_accuracy: 0.0046\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5988 - accuracy: 0.0074 - val_loss: 5.4602 - val_accuracy: 0.0068\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5301 - accuracy: 0.0078 - val_loss: 5.4172 - val_accuracy: 0.0074\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4635 - accuracy: 0.0072 - val_loss: 5.3405 - val_accuracy: 0.0084\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4189 - accuracy: 0.0081 - val_loss: 5.3738 - val_accuracy: 0.0074\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3783 - accuracy: 0.0078 - val_loss: 5.3267 - val_accuracy: 0.0104\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3483 - accuracy: 0.0090 - val_loss: 5.3140 - val_accuracy: 0.0084\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3201 - accuracy: 0.0092 - val_loss: 5.2872 - val_accuracy: 0.0102\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2990 - accuracy: 0.0093 - val_loss: 5.4759 - val_accuracy: 0.0066\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2793 - accuracy: 0.0091 - val_loss: 5.2124 - val_accuracy: 0.0112\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2566 - accuracy: 0.0094 - val_loss: 5.1574 - val_accuracy: 0.0094\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2362 - accuracy: 0.0105 - val_loss: 5.1477 - val_accuracy: 0.0094\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2091 - accuracy: 0.0108 - val_loss: 5.4335 - val_accuracy: 0.0076\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1928 - accuracy: 0.0112 - val_loss: 5.2206 - val_accuracy: 0.0132\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1705 - accuracy: 0.0117 - val_loss: 5.4665 - val_accuracy: 0.0102\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1535 - accuracy: 0.0119 - val_loss: 5.6093 - val_accuracy: 0.0102\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1293 - accuracy: 0.0143 - val_loss: 5.1179 - val_accuracy: 0.0176\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1022 - accuracy: 0.0151 - val_loss: 5.0542 - val_accuracy: 0.0204\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0757 - accuracy: 0.0154 - val_loss: 4.9991 - val_accuracy: 0.0250\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0424 - accuracy: 0.0182 - val_loss: 5.1711 - val_accuracy: 0.0188\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0133 - accuracy: 0.0186 - val_loss: 4.9489 - val_accuracy: 0.0238\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9812 - accuracy: 0.0213 - val_loss: 4.8945 - val_accuracy: 0.0294\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9553 - accuracy: 0.0214 - val_loss: 4.8768 - val_accuracy: 0.0280\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9251 - accuracy: 0.0221 - val_loss: 4.8632 - val_accuracy: 0.0294\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8934 - accuracy: 0.0227 - val_loss: 4.8388 - val_accuracy: 0.0312\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8762 - accuracy: 0.0232 - val_loss: 4.7245 - val_accuracy: 0.0364\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8525 - accuracy: 0.0240 - val_loss: 4.6965 - val_accuracy: 0.0340\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8285 - accuracy: 0.0238 - val_loss: 5.0017 - val_accuracy: 0.0216\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8079 - accuracy: 0.0255 - val_loss: 4.7163 - val_accuracy: 0.0320\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7897 - accuracy: 0.0280 - val_loss: 4.7467 - val_accuracy: 0.0304\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7739 - accuracy: 0.0265 - val_loss: 4.6699 - val_accuracy: 0.0364\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7577 - accuracy: 0.0270 - val_loss: 4.7124 - val_accuracy: 0.0326\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7428 - accuracy: 0.0270 - val_loss: 4.6687 - val_accuracy: 0.0348\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7273 - accuracy: 0.0282 - val_loss: 5.2107 - val_accuracy: 0.0170\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7151 - accuracy: 0.0282 - val_loss: 4.6737 - val_accuracy: 0.0332\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7035 - accuracy: 0.0301 - val_loss: 4.8703 - val_accuracy: 0.0226\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6887 - accuracy: 0.0294 - val_loss: 4.6247 - val_accuracy: 0.0328\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6760 - accuracy: 0.0297 - val_loss: 4.7700 - val_accuracy: 0.0298\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6665 - accuracy: 0.0292 - val_loss: 4.5052 - val_accuracy: 0.0444\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6552 - accuracy: 0.0315 - val_loss: 4.5439 - val_accuracy: 0.0402\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6465 - accuracy: 0.0303 - val_loss: 4.5995 - val_accuracy: 0.0358\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6329 - accuracy: 0.0300 - val_loss: 4.5211 - val_accuracy: 0.0416\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6229 - accuracy: 0.0322 - val_loss: 4.5662 - val_accuracy: 0.0370\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6098 - accuracy: 0.0304 - val_loss: 4.4720 - val_accuracy: 0.0438\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6038 - accuracy: 0.0313 - val_loss: 4.8031 - val_accuracy: 0.0220\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5936 - accuracy: 0.0337 - val_loss: 4.7564 - val_accuracy: 0.0268\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5863 - accuracy: 0.0323 - val_loss: 4.4386 - val_accuracy: 0.0500\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5798 - accuracy: 0.0328 - val_loss: 4.5004 - val_accuracy: 0.0448\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5685 - accuracy: 0.0344 - val_loss: 4.4775 - val_accuracy: 0.0420\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5626 - accuracy: 0.0337 - val_loss: 4.4894 - val_accuracy: 0.0398\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5502 - accuracy: 0.0337 - val_loss: 4.6019 - val_accuracy: 0.0296\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5470 - accuracy: 0.0345 - val_loss: 4.5338 - val_accuracy: 0.0366\n",
      "\n",
      "***** Individual 6/6 *****\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 6.0684 - accuracy: 0.0041 - val_loss: 5.7976 - val_accuracy: 0.0056\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 6.0139 - accuracy: 0.0043 - val_loss: 5.7804 - val_accuracy: 0.0052\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.9709 - accuracy: 0.0043 - val_loss: 5.7774 - val_accuracy: 0.0044\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.9390 - accuracy: 0.0053 - val_loss: 5.7474 - val_accuracy: 0.0058\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.9031 - accuracy: 0.0050 - val_loss: 5.7036 - val_accuracy: 0.0066\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.8634 - accuracy: 0.0062 - val_loss: 5.6733 - val_accuracy: 0.0066\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.8242 - accuracy: 0.0072 - val_loss: 5.6322 - val_accuracy: 0.0072\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.7874 - accuracy: 0.0075 - val_loss: 5.5960 - val_accuracy: 0.0072\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.7490 - accuracy: 0.0086 - val_loss: 5.5614 - val_accuracy: 0.0094\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.7190 - accuracy: 0.0085 - val_loss: 5.5257 - val_accuracy: 0.0090\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.6796 - accuracy: 0.0090 - val_loss: 5.5109 - val_accuracy: 0.0078\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.6354 - accuracy: 0.0099 - val_loss: 5.4664 - val_accuracy: 0.0114\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.6071 - accuracy: 0.0096 - val_loss: 5.4421 - val_accuracy: 0.0092\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5838 - accuracy: 0.0104 - val_loss: 5.4285 - val_accuracy: 0.0118\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5551 - accuracy: 0.0103 - val_loss: 5.3950 - val_accuracy: 0.0132\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5303 - accuracy: 0.0105 - val_loss: 5.3863 - val_accuracy: 0.0114\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4995 - accuracy: 0.0108 - val_loss: 5.3739 - val_accuracy: 0.0098\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4788 - accuracy: 0.0107 - val_loss: 5.3465 - val_accuracy: 0.0118\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4522 - accuracy: 0.0132 - val_loss: 5.3327 - val_accuracy: 0.0104\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4379 - accuracy: 0.0127 - val_loss: 5.3081 - val_accuracy: 0.0138\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4183 - accuracy: 0.0121 - val_loss: 5.2926 - val_accuracy: 0.0140\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3978 - accuracy: 0.0127 - val_loss: 5.2853 - val_accuracy: 0.0114\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3831 - accuracy: 0.0123 - val_loss: 5.2741 - val_accuracy: 0.0114\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3589 - accuracy: 0.0132 - val_loss: 5.2511 - val_accuracy: 0.0132\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3428 - accuracy: 0.0140 - val_loss: 5.2352 - val_accuracy: 0.0160\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3261 - accuracy: 0.0149 - val_loss: 5.2186 - val_accuracy: 0.0170\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3109 - accuracy: 0.0142 - val_loss: 5.2135 - val_accuracy: 0.0182\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2999 - accuracy: 0.0152 - val_loss: 5.1915 - val_accuracy: 0.0166\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2806 - accuracy: 0.0162 - val_loss: 5.1696 - val_accuracy: 0.0200\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2699 - accuracy: 0.0162 - val_loss: 5.1564 - val_accuracy: 0.0194\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2572 - accuracy: 0.0170 - val_loss: 5.1446 - val_accuracy: 0.0212\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2414 - accuracy: 0.0167 - val_loss: 5.1431 - val_accuracy: 0.0224\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2275 - accuracy: 0.0162 - val_loss: 5.1356 - val_accuracy: 0.0188\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2257 - accuracy: 0.0171 - val_loss: 5.1315 - val_accuracy: 0.0182\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2074 - accuracy: 0.0186 - val_loss: 5.1155 - val_accuracy: 0.0226\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1958 - accuracy: 0.0186 - val_loss: 5.1300 - val_accuracy: 0.0192\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1898 - accuracy: 0.0182 - val_loss: 5.1167 - val_accuracy: 0.0206\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1846 - accuracy: 0.0182 - val_loss: 5.1037 - val_accuracy: 0.0230\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1722 - accuracy: 0.0194 - val_loss: 5.1087 - val_accuracy: 0.0222\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1574 - accuracy: 0.0206 - val_loss: 5.0848 - val_accuracy: 0.0232\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1474 - accuracy: 0.0200 - val_loss: 5.0753 - val_accuracy: 0.0232\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1420 - accuracy: 0.0211 - val_loss: 5.0648 - val_accuracy: 0.0230\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1370 - accuracy: 0.0206 - val_loss: 5.0728 - val_accuracy: 0.0232\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1251 - accuracy: 0.0202 - val_loss: 5.0540 - val_accuracy: 0.0242\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1195 - accuracy: 0.0217 - val_loss: 5.0560 - val_accuracy: 0.0228\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1158 - accuracy: 0.0211 - val_loss: 5.0545 - val_accuracy: 0.0226\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1085 - accuracy: 0.0205 - val_loss: 5.0406 - val_accuracy: 0.0248\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0985 - accuracy: 0.0224 - val_loss: 5.0395 - val_accuracy: 0.0244\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0958 - accuracy: 0.0217 - val_loss: 5.0356 - val_accuracy: 0.0228\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0843 - accuracy: 0.0222 - val_loss: 5.0331 - val_accuracy: 0.0248\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0805 - accuracy: 0.0220 - val_loss: 5.0374 - val_accuracy: 0.0250\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0742 - accuracy: 0.0234 - val_loss: 5.0206 - val_accuracy: 0.0262\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0712 - accuracy: 0.0234 - val_loss: 5.0140 - val_accuracy: 0.0250\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0589 - accuracy: 0.0224 - val_loss: 5.0159 - val_accuracy: 0.0290\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0577 - accuracy: 0.0222 - val_loss: 5.0111 - val_accuracy: 0.0250\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0506 - accuracy: 0.0232 - val_loss: 5.0143 - val_accuracy: 0.0274\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0433 - accuracy: 0.0231 - val_loss: 5.0029 - val_accuracy: 0.0252\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0401 - accuracy: 0.0242 - val_loss: 4.9917 - val_accuracy: 0.0272\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0311 - accuracy: 0.0258 - val_loss: 4.9971 - val_accuracy: 0.0278\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0292 - accuracy: 0.0240 - val_loss: 4.9857 - val_accuracy: 0.0274\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0196 - accuracy: 0.0235 - val_loss: 4.9716 - val_accuracy: 0.0304\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0175 - accuracy: 0.0245 - val_loss: 4.9907 - val_accuracy: 0.0312\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0109 - accuracy: 0.0248 - val_loss: 4.9818 - val_accuracy: 0.0292\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0030 - accuracy: 0.0264 - val_loss: 4.9769 - val_accuracy: 0.0278\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9960 - accuracy: 0.0250 - val_loss: 4.9613 - val_accuracy: 0.0268\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9881 - accuracy: 0.0253 - val_loss: 4.9589 - val_accuracy: 0.0262\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9859 - accuracy: 0.0272 - val_loss: 4.9725 - val_accuracy: 0.0262\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9853 - accuracy: 0.0254 - val_loss: 4.9587 - val_accuracy: 0.0288\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9787 - accuracy: 0.0263 - val_loss: 4.9529 - val_accuracy: 0.0306\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9739 - accuracy: 0.0282 - val_loss: 4.9383 - val_accuracy: 0.0268\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9680 - accuracy: 0.0276 - val_loss: 4.9437 - val_accuracy: 0.0268\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9618 - accuracy: 0.0263 - val_loss: 4.9655 - val_accuracy: 0.0248\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9575 - accuracy: 0.0272 - val_loss: 4.9322 - val_accuracy: 0.0276\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9446 - accuracy: 0.0278 - val_loss: 4.9342 - val_accuracy: 0.0280\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9432 - accuracy: 0.0283 - val_loss: 4.9278 - val_accuracy: 0.0312\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9392 - accuracy: 0.0272 - val_loss: 4.9138 - val_accuracy: 0.0324\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9297 - accuracy: 0.0281 - val_loss: 4.9200 - val_accuracy: 0.0282\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9257 - accuracy: 0.0280 - val_loss: 4.9294 - val_accuracy: 0.0332\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9201 - accuracy: 0.0294 - val_loss: 4.9133 - val_accuracy: 0.0308\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9162 - accuracy: 0.0285 - val_loss: 4.9087 - val_accuracy: 0.0280\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9083 - accuracy: 0.0287 - val_loss: 4.9109 - val_accuracy: 0.0292\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9056 - accuracy: 0.0285 - val_loss: 4.9056 - val_accuracy: 0.0310\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8958 - accuracy: 0.0316 - val_loss: 4.8941 - val_accuracy: 0.0326\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8913 - accuracy: 0.0316 - val_loss: 4.9150 - val_accuracy: 0.0296\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8942 - accuracy: 0.0308 - val_loss: 4.8959 - val_accuracy: 0.0322\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8796 - accuracy: 0.0309 - val_loss: 4.8703 - val_accuracy: 0.0310\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8817 - accuracy: 0.0300 - val_loss: 4.8716 - val_accuracy: 0.0326\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8768 - accuracy: 0.0320 - val_loss: 4.8666 - val_accuracy: 0.0308\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8675 - accuracy: 0.0308 - val_loss: 4.8685 - val_accuracy: 0.0316\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8609 - accuracy: 0.0328 - val_loss: 4.8787 - val_accuracy: 0.0316\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8574 - accuracy: 0.0317 - val_loss: 4.8498 - val_accuracy: 0.0334\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8555 - accuracy: 0.0308 - val_loss: 4.8631 - val_accuracy: 0.0354\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8440 - accuracy: 0.0311 - val_loss: 4.8566 - val_accuracy: 0.0356\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8405 - accuracy: 0.0312 - val_loss: 4.8600 - val_accuracy: 0.0318\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8291 - accuracy: 0.0326 - val_loss: 4.8545 - val_accuracy: 0.0308\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8289 - accuracy: 0.0320 - val_loss: 4.8613 - val_accuracy: 0.0304\n",
      "\n",
      "Generation 1/2 Evaluation: [0.06800000369548798, 0.04360000044107437, 0.03799999877810478, 0.03660000115633011, 0.030400000512599945, 0.003000000026077032]\n",
      "\n",
      "-------------------- Generation 2/2 --------------------\n",
      "\n",
      "***** Individual 1/6 *****\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 3.8970 - accuracy: 0.1089 - val_loss: 4.8713 - val_accuracy: 0.0370\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.6139 - accuracy: 0.1254 - val_loss: 4.5821 - val_accuracy: 0.0528\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.5265 - accuracy: 0.1363 - val_loss: 4.5621 - val_accuracy: 0.0768\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.4685 - accuracy: 0.1436 - val_loss: 4.6191 - val_accuracy: 0.0684\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.4288 - accuracy: 0.1530 - val_loss: 4.5995 - val_accuracy: 0.0650\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.3827 - accuracy: 0.1583 - val_loss: 4.3911 - val_accuracy: 0.0716\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.3304 - accuracy: 0.1686 - val_loss: 4.5583 - val_accuracy: 0.0668\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.2783 - accuracy: 0.1771 - val_loss: 4.4521 - val_accuracy: 0.0732\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.2400 - accuracy: 0.1860 - val_loss: 4.6401 - val_accuracy: 0.0556\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.1977 - accuracy: 0.1937 - val_loss: 4.8807 - val_accuracy: 0.0548\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.1622 - accuracy: 0.2019 - val_loss: 4.2971 - val_accuracy: 0.0820\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.1140 - accuracy: 0.2083 - val_loss: 4.1854 - val_accuracy: 0.0788\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.0912 - accuracy: 0.2132 - val_loss: 4.7876 - val_accuracy: 0.0662\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.0320 - accuracy: 0.2255 - val_loss: 4.9034 - val_accuracy: 0.0646\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.0013 - accuracy: 0.2315 - val_loss: 4.5238 - val_accuracy: 0.0772\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 2.9533 - accuracy: 0.2406 - val_loss: 4.4648 - val_accuracy: 0.0852\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 2.9233 - accuracy: 0.2453 - val_loss: 4.2916 - val_accuracy: 0.0902\n",
      "\n",
      "***** Individual 2/6 *****\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 2s 2ms/step - loss: 5.7082 - accuracy: 0.0059 - val_loss: 5.5081 - val_accuracy: 0.0092\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5660 - accuracy: 0.0090 - val_loss: 5.3340 - val_accuracy: 0.0186\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4776 - accuracy: 0.0120 - val_loss: 5.2581 - val_accuracy: 0.0234\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4126 - accuracy: 0.0148 - val_loss: 5.2074 - val_accuracy: 0.0274\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3591 - accuracy: 0.0171 - val_loss: 5.1614 - val_accuracy: 0.0310\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3138 - accuracy: 0.0186 - val_loss: 5.1198 - val_accuracy: 0.0330\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2695 - accuracy: 0.0218 - val_loss: 5.0742 - val_accuracy: 0.0374\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2378 - accuracy: 0.0229 - val_loss: 5.0461 - val_accuracy: 0.0386\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1957 - accuracy: 0.0246 - val_loss: 5.0032 - val_accuracy: 0.0420\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1670 - accuracy: 0.0267 - val_loss: 4.9749 - val_accuracy: 0.0436\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1343 - accuracy: 0.0277 - val_loss: 4.9531 - val_accuracy: 0.0412\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1070 - accuracy: 0.0282 - val_loss: 4.9161 - val_accuracy: 0.0452\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0816 - accuracy: 0.0300 - val_loss: 4.9019 - val_accuracy: 0.0448\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0529 - accuracy: 0.0314 - val_loss: 4.8589 - val_accuracy: 0.0492\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0316 - accuracy: 0.0323 - val_loss: 4.8553 - val_accuracy: 0.0442\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0050 - accuracy: 0.0330 - val_loss: 4.8263 - val_accuracy: 0.0498\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9844 - accuracy: 0.0335 - val_loss: 4.8032 - val_accuracy: 0.0484\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9622 - accuracy: 0.0345 - val_loss: 4.7847 - val_accuracy: 0.0482\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9400 - accuracy: 0.0360 - val_loss: 4.7611 - val_accuracy: 0.0482\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9239 - accuracy: 0.0369 - val_loss: 4.7476 - val_accuracy: 0.0550\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9113 - accuracy: 0.0353 - val_loss: 4.7286 - val_accuracy: 0.0524\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8919 - accuracy: 0.0363 - val_loss: 4.7192 - val_accuracy: 0.0510\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8692 - accuracy: 0.0376 - val_loss: 4.6956 - val_accuracy: 0.0518\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8580 - accuracy: 0.0389 - val_loss: 4.6735 - val_accuracy: 0.0552\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8409 - accuracy: 0.0378 - val_loss: 4.6690 - val_accuracy: 0.0558\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8268 - accuracy: 0.0391 - val_loss: 4.6497 - val_accuracy: 0.0550\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8129 - accuracy: 0.0395 - val_loss: 4.6278 - val_accuracy: 0.0542\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8021 - accuracy: 0.0399 - val_loss: 4.6165 - val_accuracy: 0.0538\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7842 - accuracy: 0.0412 - val_loss: 4.6031 - val_accuracy: 0.0582\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7723 - accuracy: 0.0427 - val_loss: 4.5974 - val_accuracy: 0.0562\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7605 - accuracy: 0.0426 - val_loss: 4.5947 - val_accuracy: 0.0556\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7494 - accuracy: 0.0424 - val_loss: 4.5722 - val_accuracy: 0.0600\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7332 - accuracy: 0.0427 - val_loss: 4.5775 - val_accuracy: 0.0542\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7268 - accuracy: 0.0436 - val_loss: 4.5544 - val_accuracy: 0.0598\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7160 - accuracy: 0.0437 - val_loss: 4.5378 - val_accuracy: 0.0576\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7050 - accuracy: 0.0439 - val_loss: 4.5314 - val_accuracy: 0.0588\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6912 - accuracy: 0.0454 - val_loss: 4.5206 - val_accuracy: 0.0586\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6872 - accuracy: 0.0437 - val_loss: 4.5088 - val_accuracy: 0.0584\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6766 - accuracy: 0.0445 - val_loss: 4.5050 - val_accuracy: 0.0590\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6698 - accuracy: 0.0452 - val_loss: 4.5023 - val_accuracy: 0.0610\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6530 - accuracy: 0.0465 - val_loss: 4.4889 - val_accuracy: 0.0596\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6485 - accuracy: 0.0465 - val_loss: 4.4701 - val_accuracy: 0.0604\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6407 - accuracy: 0.0458 - val_loss: 4.4874 - val_accuracy: 0.0610\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6291 - accuracy: 0.0471 - val_loss: 4.4580 - val_accuracy: 0.0616\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6192 - accuracy: 0.0486 - val_loss: 4.4475 - val_accuracy: 0.0608\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6113 - accuracy: 0.0477 - val_loss: 4.4517 - val_accuracy: 0.0594\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5980 - accuracy: 0.0484 - val_loss: 4.4434 - val_accuracy: 0.0674\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5929 - accuracy: 0.0479 - val_loss: 4.4453 - val_accuracy: 0.0644\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5815 - accuracy: 0.0491 - val_loss: 4.4231 - val_accuracy: 0.0670\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5820 - accuracy: 0.0493 - val_loss: 4.4158 - val_accuracy: 0.0626\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5740 - accuracy: 0.0476 - val_loss: 4.4055 - val_accuracy: 0.0656\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5686 - accuracy: 0.0508 - val_loss: 4.4060 - val_accuracy: 0.0622\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5564 - accuracy: 0.0494 - val_loss: 4.3945 - val_accuracy: 0.0624\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5498 - accuracy: 0.0526 - val_loss: 4.3809 - val_accuracy: 0.0658\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5474 - accuracy: 0.0491 - val_loss: 4.3790 - val_accuracy: 0.0666\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5382 - accuracy: 0.0500 - val_loss: 4.3856 - val_accuracy: 0.0608\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5331 - accuracy: 0.0524 - val_loss: 4.3751 - val_accuracy: 0.0656\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5289 - accuracy: 0.0512 - val_loss: 4.3554 - val_accuracy: 0.0708\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5150 - accuracy: 0.0532 - val_loss: 4.3699 - val_accuracy: 0.0644\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5115 - accuracy: 0.0515 - val_loss: 4.3439 - val_accuracy: 0.0680\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5006 - accuracy: 0.0517 - val_loss: 4.3367 - val_accuracy: 0.0674\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4995 - accuracy: 0.0556 - val_loss: 4.3496 - val_accuracy: 0.0632\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4902 - accuracy: 0.0525 - val_loss: 4.3249 - val_accuracy: 0.0638\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4914 - accuracy: 0.0519 - val_loss: 4.3243 - val_accuracy: 0.0686\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4854 - accuracy: 0.0537 - val_loss: 4.3433 - val_accuracy: 0.0656\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4782 - accuracy: 0.0529 - val_loss: 4.3248 - val_accuracy: 0.0694\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4774 - accuracy: 0.0546 - val_loss: 4.3172 - val_accuracy: 0.0664\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4653 - accuracy: 0.0548 - val_loss: 4.3065 - val_accuracy: 0.0684\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4582 - accuracy: 0.0554 - val_loss: 4.3396 - val_accuracy: 0.0660\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4606 - accuracy: 0.0546 - val_loss: 4.2909 - val_accuracy: 0.0712\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4534 - accuracy: 0.0544 - val_loss: 4.2960 - val_accuracy: 0.0718\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4441 - accuracy: 0.0554 - val_loss: 4.3150 - val_accuracy: 0.0682\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4392 - accuracy: 0.0569 - val_loss: 4.3040 - val_accuracy: 0.0666\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4298 - accuracy: 0.0570 - val_loss: 4.2787 - val_accuracy: 0.0668\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4236 - accuracy: 0.0562 - val_loss: 4.2811 - val_accuracy: 0.0690\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4194 - accuracy: 0.0578 - val_loss: 4.2711 - val_accuracy: 0.0726\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4177 - accuracy: 0.0563 - val_loss: 4.2708 - val_accuracy: 0.0724\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4168 - accuracy: 0.0570 - val_loss: 4.2702 - val_accuracy: 0.0656\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4041 - accuracy: 0.0570 - val_loss: 4.2632 - val_accuracy: 0.0692\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3962 - accuracy: 0.0592 - val_loss: 4.2709 - val_accuracy: 0.0738\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3956 - accuracy: 0.0585 - val_loss: 4.2705 - val_accuracy: 0.0682\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3943 - accuracy: 0.0584 - val_loss: 4.2432 - val_accuracy: 0.0730\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3863 - accuracy: 0.0593 - val_loss: 4.2726 - val_accuracy: 0.0682\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3800 - accuracy: 0.0594 - val_loss: 4.2496 - val_accuracy: 0.0692\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3844 - accuracy: 0.0586 - val_loss: 4.2385 - val_accuracy: 0.0726\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3709 - accuracy: 0.0592 - val_loss: 4.2337 - val_accuracy: 0.0712\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3666 - accuracy: 0.0612 - val_loss: 4.2282 - val_accuracy: 0.0742\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3609 - accuracy: 0.0600 - val_loss: 4.2238 - val_accuracy: 0.0706\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3635 - accuracy: 0.0608 - val_loss: 4.2217 - val_accuracy: 0.0740\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3557 - accuracy: 0.0599 - val_loss: 4.2186 - val_accuracy: 0.0722\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3499 - accuracy: 0.0612 - val_loss: 4.2084 - val_accuracy: 0.0738\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3474 - accuracy: 0.0618 - val_loss: 4.2170 - val_accuracy: 0.0710\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3373 - accuracy: 0.0613 - val_loss: 4.2380 - val_accuracy: 0.0740\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3363 - accuracy: 0.0639 - val_loss: 4.2187 - val_accuracy: 0.0724\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3343 - accuracy: 0.0615 - val_loss: 4.1902 - val_accuracy: 0.0762\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3244 - accuracy: 0.0617 - val_loss: 4.1823 - val_accuracy: 0.0742\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3273 - accuracy: 0.0627 - val_loss: 4.1908 - val_accuracy: 0.0738\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3249 - accuracy: 0.0629 - val_loss: 4.2005 - val_accuracy: 0.0732\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3189 - accuracy: 0.0634 - val_loss: 4.1818 - val_accuracy: 0.0708\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3179 - accuracy: 0.0615 - val_loss: 4.1769 - val_accuracy: 0.0778\n",
      "\n",
      "***** Individual 3/6 *****\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 5.4278 - accuracy: 0.0248 - val_loss: 5.4945 - val_accuracy: 0.0200\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 4.9815 - accuracy: 0.0739 - val_loss: 5.1031 - val_accuracy: 0.0334\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 4.6620 - accuracy: 0.1061 - val_loss: 4.9402 - val_accuracy: 0.0370\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 4.4295 - accuracy: 0.1339 - val_loss: 4.8434 - val_accuracy: 0.0406\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 4.2635 - accuracy: 0.1524 - val_loss: 4.7840 - val_accuracy: 0.0422\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 4.1268 - accuracy: 0.1750 - val_loss: 4.7635 - val_accuracy: 0.0410\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 4.0216 - accuracy: 0.1902 - val_loss: 4.7703 - val_accuracy: 0.0426\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.9277 - accuracy: 0.2054 - val_loss: 4.7600 - val_accuracy: 0.0420\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.8382 - accuracy: 0.2210 - val_loss: 4.7802 - val_accuracy: 0.0410\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.7612 - accuracy: 0.2344 - val_loss: 4.8047 - val_accuracy: 0.0426\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.6930 - accuracy: 0.2463 - val_loss: 4.8182 - val_accuracy: 0.0444\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.6312 - accuracy: 0.2556 - val_loss: 4.8553 - val_accuracy: 0.0442\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 3.5619 - accuracy: 0.2694 - val_loss: 4.8349 - val_accuracy: 0.0454\n",
      "\n",
      "***** Individual 4/6 *****\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1476 - accuracy: 0.0196 - val_loss: 7.6895 - val_accuracy: 0.0130\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4841 - accuracy: 0.0480 - val_loss: 7.4552 - val_accuracy: 0.0156\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.2338 - accuracy: 0.0657 - val_loss: 5.3079 - val_accuracy: 0.0296\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.0556 - accuracy: 0.0786 - val_loss: 5.1015 - val_accuracy: 0.0312\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.9102 - accuracy: 0.0905 - val_loss: 4.9583 - val_accuracy: 0.0496\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.8009 - accuracy: 0.1019 - val_loss: 5.6886 - val_accuracy: 0.0298\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.7084 - accuracy: 0.1154 - val_loss: 4.4356 - val_accuracy: 0.0612\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.6195 - accuracy: 0.1275 - val_loss: 5.1191 - val_accuracy: 0.0350\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.5432 - accuracy: 0.1356 - val_loss: 4.7576 - val_accuracy: 0.0492\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.4722 - accuracy: 0.1474 - val_loss: 5.0192 - val_accuracy: 0.0514\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.4050 - accuracy: 0.1581 - val_loss: 4.3873 - val_accuracy: 0.0650\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.3428 - accuracy: 0.1699 - val_loss: 4.3480 - val_accuracy: 0.0676\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.2789 - accuracy: 0.1817 - val_loss: 4.1667 - val_accuracy: 0.0848\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.2065 - accuracy: 0.1925 - val_loss: 4.7507 - val_accuracy: 0.0670\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.1515 - accuracy: 0.2018 - val_loss: 4.6545 - val_accuracy: 0.0666\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.0797 - accuracy: 0.2158 - val_loss: 4.4108 - val_accuracy: 0.0864\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.0140 - accuracy: 0.2272 - val_loss: 4.2602 - val_accuracy: 0.0830\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 2.9617 - accuracy: 0.2361 - val_loss: 4.4933 - val_accuracy: 0.0828\n",
      "\n",
      "***** Individual 5/6 *****\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0383 - accuracy: 0.0230 - val_loss: 5.3835 - val_accuracy: 0.0242\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4073 - accuracy: 0.0515 - val_loss: 6.0585 - val_accuracy: 0.0222\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.1490 - accuracy: 0.0690 - val_loss: 5.0252 - val_accuracy: 0.0356\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.9676 - accuracy: 0.0829 - val_loss: 4.6155 - val_accuracy: 0.0548\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.8339 - accuracy: 0.0953 - val_loss: 5.1168 - val_accuracy: 0.0488\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.7378 - accuracy: 0.1055 - val_loss: 4.4759 - val_accuracy: 0.0590\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.6495 - accuracy: 0.1178 - val_loss: 4.3375 - val_accuracy: 0.0732\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.5686 - accuracy: 0.1282 - val_loss: 4.4847 - val_accuracy: 0.0620\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.4960 - accuracy: 0.1372 - val_loss: 5.0792 - val_accuracy: 0.0398\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.4290 - accuracy: 0.1492 - val_loss: 5.6250 - val_accuracy: 0.0394\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.3785 - accuracy: 0.1578 - val_loss: 4.6726 - val_accuracy: 0.0566\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.3132 - accuracy: 0.1660 - val_loss: 4.1099 - val_accuracy: 0.0790\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.2464 - accuracy: 0.1781 - val_loss: 4.3508 - val_accuracy: 0.0738\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.1813 - accuracy: 0.1894 - val_loss: 4.7982 - val_accuracy: 0.0584\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.1252 - accuracy: 0.2004 - val_loss: 4.8047 - val_accuracy: 0.0586\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 3.0638 - accuracy: 0.2098 - val_loss: 4.3427 - val_accuracy: 0.0816\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 2.9969 - accuracy: 0.2251 - val_loss: 4.4835 - val_accuracy: 0.0782\n",
      "\n",
      "***** Individual 6/6 *****\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 6.0418 - accuracy: 0.0040 - val_loss: 5.7992 - val_accuracy: 0.0044\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.9648 - accuracy: 0.0049 - val_loss: 5.7466 - val_accuracy: 0.0054\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.9017 - accuracy: 0.0062 - val_loss: 5.7053 - val_accuracy: 0.0064\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.8464 - accuracy: 0.0079 - val_loss: 5.6578 - val_accuracy: 0.0080\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.7897 - accuracy: 0.0084 - val_loss: 5.6168 - val_accuracy: 0.0080\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.7255 - accuracy: 0.0090 - val_loss: 5.5706 - val_accuracy: 0.0070\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.6781 - accuracy: 0.0112 - val_loss: 5.5312 - val_accuracy: 0.0088\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.6345 - accuracy: 0.0121 - val_loss: 5.5025 - val_accuracy: 0.0090\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5932 - accuracy: 0.0112 - val_loss: 5.4643 - val_accuracy: 0.0098\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5517 - accuracy: 0.0128 - val_loss: 5.4390 - val_accuracy: 0.0114\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.5164 - accuracy: 0.0137 - val_loss: 5.4095 - val_accuracy: 0.0098\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4869 - accuracy: 0.0146 - val_loss: 5.3819 - val_accuracy: 0.0108\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4560 - accuracy: 0.0154 - val_loss: 5.3578 - val_accuracy: 0.0126\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.4261 - accuracy: 0.0167 - val_loss: 5.3352 - val_accuracy: 0.0114\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3945 - accuracy: 0.0167 - val_loss: 5.3167 - val_accuracy: 0.0142\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3718 - accuracy: 0.0184 - val_loss: 5.2918 - val_accuracy: 0.0152\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3434 - accuracy: 0.0193 - val_loss: 5.2727 - val_accuracy: 0.0150\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.3136 - accuracy: 0.0184 - val_loss: 5.2545 - val_accuracy: 0.0154\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2884 - accuracy: 0.0205 - val_loss: 5.2323 - val_accuracy: 0.0162\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2533 - accuracy: 0.0206 - val_loss: 5.2075 - val_accuracy: 0.0176\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2298 - accuracy: 0.0240 - val_loss: 5.1913 - val_accuracy: 0.0184\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.2067 - accuracy: 0.0239 - val_loss: 5.1681 - val_accuracy: 0.0206\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1835 - accuracy: 0.0260 - val_loss: 5.1526 - val_accuracy: 0.0192\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1655 - accuracy: 0.0256 - val_loss: 5.1380 - val_accuracy: 0.0196\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1481 - accuracy: 0.0267 - val_loss: 5.1250 - val_accuracy: 0.0238\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.1199 - accuracy: 0.0264 - val_loss: 5.0920 - val_accuracy: 0.0212\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0974 - accuracy: 0.0284 - val_loss: 5.0788 - val_accuracy: 0.0224\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0765 - accuracy: 0.0286 - val_loss: 5.0644 - val_accuracy: 0.0232\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0599 - accuracy: 0.0300 - val_loss: 5.0481 - val_accuracy: 0.0224\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0355 - accuracy: 0.0305 - val_loss: 5.0295 - val_accuracy: 0.0254\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 5.0160 - accuracy: 0.0311 - val_loss: 5.0142 - val_accuracy: 0.0262\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9949 - accuracy: 0.0336 - val_loss: 5.0034 - val_accuracy: 0.0284\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9824 - accuracy: 0.0348 - val_loss: 4.9866 - val_accuracy: 0.0270\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9642 - accuracy: 0.0340 - val_loss: 4.9741 - val_accuracy: 0.0282\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9454 - accuracy: 0.0366 - val_loss: 4.9624 - val_accuracy: 0.0276\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9244 - accuracy: 0.0356 - val_loss: 4.9457 - val_accuracy: 0.0276\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.9018 - accuracy: 0.0372 - val_loss: 4.9323 - val_accuracy: 0.0292\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8968 - accuracy: 0.0375 - val_loss: 4.9238 - val_accuracy: 0.0268\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8849 - accuracy: 0.0400 - val_loss: 4.9102 - val_accuracy: 0.0298\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8604 - accuracy: 0.0406 - val_loss: 4.8979 - val_accuracy: 0.0322\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8462 - accuracy: 0.0403 - val_loss: 4.8937 - val_accuracy: 0.0314\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8327 - accuracy: 0.0405 - val_loss: 4.8861 - val_accuracy: 0.0316\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8167 - accuracy: 0.0410 - val_loss: 4.8714 - val_accuracy: 0.0336\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.8026 - accuracy: 0.0438 - val_loss: 4.8578 - val_accuracy: 0.0310\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7922 - accuracy: 0.0437 - val_loss: 4.8515 - val_accuracy: 0.0326\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7757 - accuracy: 0.0435 - val_loss: 4.8382 - val_accuracy: 0.0346\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7717 - accuracy: 0.0436 - val_loss: 4.8340 - val_accuracy: 0.0312\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7550 - accuracy: 0.0457 - val_loss: 4.8265 - val_accuracy: 0.0332\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7399 - accuracy: 0.0464 - val_loss: 4.8172 - val_accuracy: 0.0346\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7256 - accuracy: 0.0466 - val_loss: 4.8148 - val_accuracy: 0.0360\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7180 - accuracy: 0.0467 - val_loss: 4.8045 - val_accuracy: 0.0358\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.7050 - accuracy: 0.0499 - val_loss: 4.7945 - val_accuracy: 0.0366\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6908 - accuracy: 0.0484 - val_loss: 4.7889 - val_accuracy: 0.0348\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6874 - accuracy: 0.0494 - val_loss: 4.7889 - val_accuracy: 0.0358\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6726 - accuracy: 0.0503 - val_loss: 4.7742 - val_accuracy: 0.0380\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6649 - accuracy: 0.0510 - val_loss: 4.7681 - val_accuracy: 0.0364\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6478 - accuracy: 0.0534 - val_loss: 4.7606 - val_accuracy: 0.0384\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6443 - accuracy: 0.0528 - val_loss: 4.7561 - val_accuracy: 0.0368\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6327 - accuracy: 0.0539 - val_loss: 4.7482 - val_accuracy: 0.0362\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6199 - accuracy: 0.0552 - val_loss: 4.7459 - val_accuracy: 0.0368\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6138 - accuracy: 0.0561 - val_loss: 4.7354 - val_accuracy: 0.0386\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.6038 - accuracy: 0.0564 - val_loss: 4.7280 - val_accuracy: 0.0390\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5938 - accuracy: 0.0541 - val_loss: 4.7236 - val_accuracy: 0.0382\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5865 - accuracy: 0.0567 - val_loss: 4.7189 - val_accuracy: 0.0372\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5747 - accuracy: 0.0581 - val_loss: 4.7174 - val_accuracy: 0.0384\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5622 - accuracy: 0.0583 - val_loss: 4.7039 - val_accuracy: 0.0422\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5534 - accuracy: 0.0590 - val_loss: 4.6996 - val_accuracy: 0.0384\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5488 - accuracy: 0.0596 - val_loss: 4.6971 - val_accuracy: 0.0380\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5398 - accuracy: 0.0602 - val_loss: 4.6916 - val_accuracy: 0.0384\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5279 - accuracy: 0.0611 - val_loss: 4.6838 - val_accuracy: 0.0396\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5191 - accuracy: 0.0631 - val_loss: 4.6823 - val_accuracy: 0.0404\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5143 - accuracy: 0.0619 - val_loss: 4.6800 - val_accuracy: 0.0408\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.5057 - accuracy: 0.0627 - val_loss: 4.6719 - val_accuracy: 0.0432\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4980 - accuracy: 0.0642 - val_loss: 4.6713 - val_accuracy: 0.0416\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4892 - accuracy: 0.0644 - val_loss: 4.6654 - val_accuracy: 0.0412\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4847 - accuracy: 0.0670 - val_loss: 4.6668 - val_accuracy: 0.0424\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4719 - accuracy: 0.0673 - val_loss: 4.6599 - val_accuracy: 0.0372\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4648 - accuracy: 0.0669 - val_loss: 4.6539 - val_accuracy: 0.0454\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4611 - accuracy: 0.0672 - val_loss: 4.6482 - val_accuracy: 0.0416\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4501 - accuracy: 0.0678 - val_loss: 4.6415 - val_accuracy: 0.0440\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4433 - accuracy: 0.0683 - val_loss: 4.6389 - val_accuracy: 0.0428\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4374 - accuracy: 0.0688 - val_loss: 4.6370 - val_accuracy: 0.0404\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4225 - accuracy: 0.0709 - val_loss: 4.6330 - val_accuracy: 0.0464\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4186 - accuracy: 0.0728 - val_loss: 4.6416 - val_accuracy: 0.0440\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4126 - accuracy: 0.0723 - val_loss: 4.6272 - val_accuracy: 0.0444\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.4056 - accuracy: 0.0724 - val_loss: 4.6271 - val_accuracy: 0.0440\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3939 - accuracy: 0.0749 - val_loss: 4.6262 - val_accuracy: 0.0444\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3959 - accuracy: 0.0723 - val_loss: 4.6226 - val_accuracy: 0.0442\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3815 - accuracy: 0.0745 - val_loss: 4.6149 - val_accuracy: 0.0460\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3770 - accuracy: 0.0747 - val_loss: 4.6103 - val_accuracy: 0.0444\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3700 - accuracy: 0.0753 - val_loss: 4.6095 - val_accuracy: 0.0428\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3600 - accuracy: 0.0780 - val_loss: 4.6115 - val_accuracy: 0.0468\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3533 - accuracy: 0.0771 - val_loss: 4.6035 - val_accuracy: 0.0478\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3517 - accuracy: 0.0782 - val_loss: 4.6017 - val_accuracy: 0.0470\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3450 - accuracy: 0.0791 - val_loss: 4.5933 - val_accuracy: 0.0466\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3325 - accuracy: 0.0796 - val_loss: 4.5940 - val_accuracy: 0.0466\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3336 - accuracy: 0.0804 - val_loss: 4.5992 - val_accuracy: 0.0456\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3279 - accuracy: 0.0785 - val_loss: 4.5908 - val_accuracy: 0.0446\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3173 - accuracy: 0.0823 - val_loss: 4.5869 - val_accuracy: 0.0476\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 4.3149 - accuracy: 0.0809 - val_loss: 4.5814 - val_accuracy: 0.0466\n",
      "\n",
      "Generation 2/2 Evaluation: [0.09019999951124191, 0.0828000009059906, 0.07819999754428864, 0.07779999822378159, 0.04659999907016754, 0.04540000110864639]\n"
     ]
    }
   ],
   "source": [
    "GENERATIONS = 2\n",
    "\n",
    "gt = GeneticTuner(hp_choices=HP_CHOICES, pop_size=6)\n",
    "population = gt.populate()\n",
    "\n",
    "for i in range(GENERATIONS):\n",
    "    print()\n",
    "    print(f'-------------------- Generation {i+1}/{GENERATIONS} --------------------')\n",
    "    \n",
    "    evaluation = gt.evaluate(population, x_train, y_train, x_val, y_val) # list of tuple Network-val_acc\n",
    "    \n",
    "    parents = gt.select(evaluation) # list of Network objects\n",
    "    \n",
    "    if i != GENERATIONS - 1:\n",
    "        population = gt.evolve(parents) # list of Network objects\n",
    "    \n",
    "    print()\n",
    "    print(f'Generation {i+1}/{GENERATIONS} Evaluation: {[ev[1] for ev in evaluation]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79d8a640-5852-4853-a847-fa81b72c0d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val_acc: 0.09019999951124191\n"
     ]
    }
   ],
   "source": [
    "evaluation.sort(key=lambda x: -x[1])\n",
    "\n",
    "best_individual, best_val_acc = evaluation[0]\n",
    "\n",
    "print(f'Best val_acc: {best_val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d867aa06-9014-410e-91b6-a732a17313bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling traces: 100%|██████████| 50000/50000 [00:21<00:00, 2306.44it/s]\n"
     ]
    }
   ],
   "source": [
    "test_th = TraceHandler('/prj/side_channel/PinataTraces/CURR/D1-K2_50k_500MHz + Resampled at 168MHz.trs')\n",
    "\n",
    "x_test, y_test = test_th.generate_test(BYTE_IDX) \n",
    "y_test = to_categorical(y_test, N_CLASSES)\n",
    "\n",
    "test_plaintexts = test_th.get_plaintexts()\n",
    "true_key_byte = test_th.get_key()[BYTE_IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8afc4b00-b8a4-412f-8e4d-a41f50b7408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 3.0110 - accuracy: 0.2353\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.9553 - accuracy: 0.2442\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.9291 - accuracy: 0.2493\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.8910 - accuracy: 0.2545\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.8590 - accuracy: 0.2606\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.8365 - accuracy: 0.2652\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.8104 - accuracy: 0.2694\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.7686 - accuracy: 0.2795\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.7360 - accuracy: 0.2848\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.6863 - accuracy: 0.2946\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.6862 - accuracy: 0.2944\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.6388 - accuracy: 0.3040\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.6136 - accuracy: 0.3074\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.5991 - accuracy: 0.3115\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.5539 - accuracy: 0.3192\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.5212 - accuracy: 0.3256\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.5015 - accuracy: 0.3326\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.4805 - accuracy: 0.3341\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.4449 - accuracy: 0.3468\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.4223 - accuracy: 0.3466\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.3982 - accuracy: 0.3531\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.3536 - accuracy: 0.3599\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.3362 - accuracy: 0.3630\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.3060 - accuracy: 0.3719\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.2772 - accuracy: 0.3782\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.2501 - accuracy: 0.3825\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.2303 - accuracy: 0.3856\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.1956 - accuracy: 0.3959\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.1858 - accuracy: 0.3952\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.1502 - accuracy: 0.4043\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.1105 - accuracy: 0.4137\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.1011 - accuracy: 0.4150\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.0661 - accuracy: 0.4249\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.0350 - accuracy: 0.4292\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.0215 - accuracy: 0.4330\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.9891 - accuracy: 0.4396\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.9508 - accuracy: 0.4490\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.9390 - accuracy: 0.4524\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.9189 - accuracy: 0.4586\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.8808 - accuracy: 0.4670\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.8375 - accuracy: 0.4752\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.8510 - accuracy: 0.4737\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.8079 - accuracy: 0.4848\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.7940 - accuracy: 0.4909\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.7392 - accuracy: 0.4975\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.7298 - accuracy: 0.5009\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.6978 - accuracy: 0.5116\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.6758 - accuracy: 0.5150\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.6628 - accuracy: 0.5215\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.6241 - accuracy: 0.5302\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.6087 - accuracy: 0.5319\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.5804 - accuracy: 0.5399\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.5663 - accuracy: 0.5446\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.5473 - accuracy: 0.5506\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.5300 - accuracy: 0.5529\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.5027 - accuracy: 0.5629\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.4906 - accuracy: 0.5659\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.4582 - accuracy: 0.5740\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.4478 - accuracy: 0.5745\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.4195 - accuracy: 0.5819\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.4046 - accuracy: 0.5862\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.3692 - accuracy: 0.5969\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.3772 - accuracy: 0.5953\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.3441 - accuracy: 0.6037\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.3185 - accuracy: 0.6084\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.2964 - accuracy: 0.6164\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.3034 - accuracy: 0.6153\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.2763 - accuracy: 0.6217\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.2480 - accuracy: 0.6280\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.2350 - accuracy: 0.6344\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.2125 - accuracy: 0.6388\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.1941 - accuracy: 0.6426\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.1963 - accuracy: 0.6416\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.1569 - accuracy: 0.6555\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.1479 - accuracy: 0.6574\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.1253 - accuracy: 0.6615\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.1360 - accuracy: 0.6585\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.1242 - accuracy: 0.6647\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.0870 - accuracy: 0.6734\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.0854 - accuracy: 0.6752\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.0804 - accuracy: 0.6774\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.0622 - accuracy: 0.6802\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.0486 - accuracy: 0.6859\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.0037 - accuracy: 0.6989\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.9993 - accuracy: 0.6996\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.0183 - accuracy: 0.6902\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.9958 - accuracy: 0.6979\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.9533 - accuracy: 0.7103\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.9591 - accuracy: 0.7116\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.9778 - accuracy: 0.7055\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.9439 - accuracy: 0.7157\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.9277 - accuracy: 0.7212\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.9176 - accuracy: 0.7225\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.9198 - accuracy: 0.7200\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.8989 - accuracy: 0.7278\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.8931 - accuracy: 0.7290\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.8781 - accuracy: 0.7337\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.8907 - accuracy: 0.7296\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.8492 - accuracy: 0.7415\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.8640 - accuracy: 0.7386\n"
     ]
    }
   ],
   "source": [
    "x_train_tot = train_th.get_traces()\n",
    "y_train_tot = train_th.get_specific_labels(BYTE_IDX)\n",
    "y_train_tot = to_categorical(y_train_tot, N_CLASSES)\n",
    "\n",
    "best_individual.final_train(x_train_tot, y_train_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b0ed213-27e3-4171-a277-785b5619c45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 9.6088 - accuracy: 0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:18<00:00, 275.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 9.6088 - accuracy: 0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:18<00:00, 275.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 9.6088 - accuracy: 0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:17<00:00, 279.30it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 9.6088 - accuracy: 0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:17<00:00, 279.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 9.6088 - accuracy: 0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:18<00:00, 276.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 9.6088 - accuracy: 0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:18<00:00, 276.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 9.6088 - accuracy: 0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:18<00:00, 276.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 9.6088 - accuracy: 0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:18<00:00, 275.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 9.6088 - accuracy: 0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:18<00:00, 275.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 9.6088 - accuracy: 0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:18<00:00, 275.90it/s] \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_individual.plot_guessing_entropy(x_test, y_test, test_plaintexts, true_key_byte, BYTE_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d39039-2a99-4dc8-a33b-47dc86a26b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdm32_env",
   "language": "python",
   "name": "mdm32_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
